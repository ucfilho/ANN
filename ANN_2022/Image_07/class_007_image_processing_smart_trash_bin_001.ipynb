{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnBy5tyiVouF550uxQnRpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/ANN/blob/master/ANN_2022/Image_07/class_007_image_processing_smart_trash_bin_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.feature\n",
        "from string import digits\n",
        "import seaborn as sns\n",
        "import skimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "7wNxYQBaKVJQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "JNNoeVHgb9WL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea3bxyjq-kcq",
        "outputId": "7a98a629-5b3a-4458-e946-95c7e7381f79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX\n",
            "To: /content/trash_nov_22_2018.zip\n",
            "100% 42.8M/42.8M [00:00<00:00, 193MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE='trash_nov_22_2018.zip'"
      ],
      "metadata": {
        "id": "oyLilZ2l-loH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive = zipfile.ZipFile('trash_nov_22_2018.zip', 'r')\n",
        "archive.extractall()"
      ],
      "metadata": {
        "id": "XwXGEOlF_K1c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_name=[]\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "        img_name.append(name)"
      ],
      "metadata": {
        "id": "cs5xKcmpAgOA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Img_Size = 224\n",
        "ref = 'jpg'\n",
        "notref = 'met'"
      ],
      "metadata": {
        "id": "PVPFW06o_kw8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= []  \n",
        "Y =[]\n",
        "n = len(img_name)\n",
        "i = 0\n",
        "for i in range(n):\n",
        "  name = img_name[i]\n",
        "  if(ref in name):\n",
        "    Y.append(name)\n",
        "    img = cv2.imread(name)\n",
        "    resized = cv2.resize(img, (Img_Size,Img_Size))\n",
        "    X.append(resized)\n",
        "m = len(Y)\n",
        "print(n,m)"
      ],
      "metadata": {
        "id": "lAOB3uC3JG2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d47191-23be-40c6-8058-3159eda2ec61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2527 2527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "tipos = []\n",
        "selected = 'find'\n",
        "for x in img_name:\n",
        "  result =''.join([i for i in x[:-4] if not i.isdigit()])\n",
        "  if(result != selected):\n",
        "    selected = result\n",
        "    tipos.append(selected)\n"
      ],
      "metadata": {
        "id": "5Kh0R80ndBQ0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label =[]\n",
        "for name in img_name:\n",
        "  for idx, x in enumerate(tipos):\n",
        "    if(x in name):\n",
        "      label.append(idx)"
      ],
      "metadata": {
        "id": "MejkwNSX1kOi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(label,columns=['target'])"
      ],
      "metadata": {
        "id": "GyKMP7gCScy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6): \n",
        "  df_plot= df[(df[\"target\"] == i)]\n",
        "  n= df_plot.shape[0]\n",
        "  print(tipos[i],n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CDIVizOZXv",
        "outputId": "c07d66bf-1ae9-4afa-ba61-60e889e75f88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard 403\n",
            "glass 501\n",
            "metal 410\n",
            "paper 594\n",
            "plastic 482\n",
            "trash 137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(df['target'])\n",
        "# check https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
        "#y"
      ],
      "metadata": {
        "id": "YGlSEZ5O3pkf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label"
      ],
      "metadata": {
        "id": "nZ_iIcFRNue7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "data = np.empty((n, 224, 224, 3))"
      ],
      "metadata": {
        "id": "Y0IiAVMPNZF9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pythontutorials.eu/deep-learning/transfer-learning/"
      ],
      "metadata": {
        "id": "g5xlAJuoOle1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "i = 0\n",
        "for im in X:\n",
        "    im = preprocess_input(im)\n",
        "    im = resize(im, output_shape=(224, 224))\n",
        "    data[i] = im\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "VVRS0r0UNzw8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N7fPiisPnkF",
        "outputId": "21ab8c1c-cb15-47a7-f692-66cc71741cf1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2527"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUW3uDgsU5I2",
        "outputId": "fd41f6db-f60e-4987-cfec-e568e0df9886"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "m = len(tipos)\n",
        "\n",
        "'''\n",
        "labels_tf = np.empty(n, dtype=int)\n",
        "for idx, yi in enumerate(label):\n",
        "  labels_tf[idx] = yi\n",
        "'''\n",
        "idx = 0\n",
        "labels_tf = np.empty([n,m], dtype=int)\n",
        "for yi in y.values:\n",
        "  labels_tf[idx] = yi\n",
        "  idx = idx + 1\n",
        "\n"
      ],
      "metadata": {
        "id": "rcgv-joQO61M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "model = MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "id": "EwENgCGxQVS8",
        "outputId": "65287b5f-7e0d-48b7-996f-cb8efbf60fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import decode_predictions\n",
        "\n",
        "predictions = model.predict(data)\n",
        "k = 0\n",
        "for decoded_prediction in decode_predictions(predictions, top=1):\n",
        "  \n",
        "  for name, desc, score in decoded_prediction:\n",
        "      if(k % 200 ==0):\n",
        "        print('- {} ({:.2f}%%) {}'.format(desc, 100 * score,img_name[k]))\n",
        "  k = k +1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooc62gF9QWUE",
        "outputId": "424f1e0e-9131-4e87-a3c2-c2e056af67f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 11s 37ms/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "- envelope (27.77%%) cardboard1.jpg\n",
            "- mailbag (27.79%%) cardboard201.jpg\n",
            "- velvet (10.09%%) cardboard401.jpg\n",
            "- ballpoint (13.35%%) glass198.jpg\n",
            "- spotlight (96.14%%) glass398.jpg\n",
            "- water_bottle (24.05%%) metal97.jpg\n",
            "- ashcan (71.91%%) metal297.jpg\n",
            "- syringe (20.62%%) paper87.jpg\n",
            "- shopping_cart (10.26%%) paper287.jpg\n",
            "- hand-held_computer (23.41%%) paper487.jpg\n",
            "- water_bottle (18.48%%) plastic93.jpg\n",
            "- water_bottle (60.90%%) plastic293.jpg\n",
            "- plastic_bag (69.38%%) trash11.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "D = len(tipos)\n",
        "model_output = Dense(D, activation='softmax')"
      ],
      "metadata": {
        "id": "j3I5nZ8dRYKd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = model_output(model.layers[-2].output)"
      ],
      "metadata": {
        "id": "bz08xnbiTn7e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Model\n",
        "\n",
        "model_input = model.input\n",
        "model_model = Model(inputs=model_input, outputs=model_output)"
      ],
      "metadata": {
        "id": "IqaB8H5ETs0W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_model.layers[:-1]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "n3oiO5lkTueV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "mZ2SZgLgTzq9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_model.fit(x=data, y=labels_tf, epochs=20, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9SymbkpT6tl",
        "outputId": "e921fbdf-324e-4f02-b0e0-7dd784f6a02f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "79/79 - 6s - loss: 1.0225 - accuracy: 0.6150 - 6s/epoch - 78ms/step\n",
            "Epoch 2/20\n",
            "79/79 - 3s - loss: 0.5576 - accuracy: 0.8045 - 3s/epoch - 42ms/step\n",
            "Epoch 3/20\n",
            "79/79 - 3s - loss: 0.4449 - accuracy: 0.8449 - 3s/epoch - 42ms/step\n",
            "Epoch 4/20\n",
            "79/79 - 3s - loss: 0.3755 - accuracy: 0.8678 - 3s/epoch - 43ms/step\n",
            "Epoch 5/20\n",
            "79/79 - 3s - loss: 0.3346 - accuracy: 0.8841 - 3s/epoch - 44ms/step\n",
            "Epoch 6/20\n",
            "79/79 - 3s - loss: 0.2928 - accuracy: 0.9050 - 3s/epoch - 42ms/step\n",
            "Epoch 7/20\n",
            "79/79 - 3s - loss: 0.2599 - accuracy: 0.9232 - 3s/epoch - 42ms/step\n",
            "Epoch 8/20\n",
            "79/79 - 3s - loss: 0.2319 - accuracy: 0.9315 - 3s/epoch - 42ms/step\n",
            "Epoch 9/20\n",
            "79/79 - 3s - loss: 0.2098 - accuracy: 0.9422 - 3s/epoch - 42ms/step\n",
            "Epoch 10/20\n",
            "79/79 - 3s - loss: 0.1952 - accuracy: 0.9505 - 3s/epoch - 42ms/step\n",
            "Epoch 11/20\n",
            "79/79 - 3s - loss: 0.1760 - accuracy: 0.9569 - 3s/epoch - 42ms/step\n",
            "Epoch 12/20\n",
            "79/79 - 3s - loss: 0.1654 - accuracy: 0.9628 - 3s/epoch - 42ms/step\n",
            "Epoch 13/20\n",
            "79/79 - 3s - loss: 0.1515 - accuracy: 0.9676 - 3s/epoch - 43ms/step\n",
            "Epoch 14/20\n",
            "79/79 - 3s - loss: 0.1390 - accuracy: 0.9751 - 3s/epoch - 43ms/step\n",
            "Epoch 15/20\n",
            "79/79 - 3s - loss: 0.1278 - accuracy: 0.9770 - 3s/epoch - 42ms/step\n",
            "Epoch 16/20\n",
            "79/79 - 3s - loss: 0.1227 - accuracy: 0.9782 - 3s/epoch - 42ms/step\n",
            "Epoch 17/20\n",
            "79/79 - 3s - loss: 0.1106 - accuracy: 0.9818 - 3s/epoch - 42ms/step\n",
            "Epoch 18/20\n",
            "79/79 - 3s - loss: 0.1054 - accuracy: 0.9877 - 3s/epoch - 43ms/step\n",
            "Epoch 19/20\n",
            "79/79 - 3s - loss: 0.0972 - accuracy: 0.9877 - 3s/epoch - 42ms/step\n",
            "Epoch 20/20\n",
            "79/79 - 3s - loss: 0.0897 - accuracy: 0.9905 - 3s/epoch - 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd34cd3a910>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oZpcAHqAcc2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}