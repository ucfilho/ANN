{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEDPXEuvqkpFKdcaMQ7IWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/ANN/blob/master/ANN_2022/Image_07/class_007_image_processing_smart_trash_bin_002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.feature\n",
        "from string import digits\n",
        "import seaborn as sns\n",
        "import skimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "7wNxYQBaKVJQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "JNNoeVHgb9WL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea3bxyjq-kcq",
        "outputId": "c70a7d95-9e46-4f19-dd68-8aa418c6a80d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX\n",
            "To: /content/trash_nov_22_2018.zip\n",
            "100% 42.8M/42.8M [00:00<00:00, 281MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE='trash_nov_22_2018.zip'"
      ],
      "metadata": {
        "id": "oyLilZ2l-loH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive = zipfile.ZipFile('trash_nov_22_2018.zip', 'r')\n",
        "archive.extractall()"
      ],
      "metadata": {
        "id": "XwXGEOlF_K1c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_name=[]\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "        img_name.append(name)"
      ],
      "metadata": {
        "id": "cs5xKcmpAgOA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Img_Size = 224\n",
        "ref = 'jpg'\n",
        "notref = 'met'"
      ],
      "metadata": {
        "id": "PVPFW06o_kw8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= []  \n",
        "Y =[]\n",
        "n = len(img_name)\n",
        "i = 0\n",
        "for i in range(n):\n",
        "  name = img_name[i]\n",
        "  if(ref in name):\n",
        "    Y.append(name)\n",
        "    img = cv2.imread(name)\n",
        "    resized = cv2.resize(img, (Img_Size,Img_Size))\n",
        "    X.append(resized)\n",
        "m = len(Y)\n",
        "print(n,m)"
      ],
      "metadata": {
        "id": "lAOB3uC3JG2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dfda925-8c79-4b4c-e26f-6938f3c5f6d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2527 2527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "tipos = []\n",
        "selected = 'find'\n",
        "for x in img_name:\n",
        "  result =''.join([i for i in x[:-4] if not i.isdigit()])\n",
        "  if(result != selected):\n",
        "    selected = result\n",
        "    tipos.append(selected)\n"
      ],
      "metadata": {
        "id": "5Kh0R80ndBQ0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label =[]\n",
        "for name in img_name:\n",
        "  for idx, x in enumerate(tipos):\n",
        "    if(x in name):\n",
        "      label.append(idx)"
      ],
      "metadata": {
        "id": "MejkwNSX1kOi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(label,columns=['target'])"
      ],
      "metadata": {
        "id": "GyKMP7gCScy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6): \n",
        "  df_plot= df[(df[\"target\"] == i)]\n",
        "  n= df_plot.shape[0]\n",
        "  print(tipos[i],n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CDIVizOZXv",
        "outputId": "555cb6dc-e975-4fc5-e4b5-adbca2872db9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard 403\n",
            "glass 501\n",
            "metal 410\n",
            "paper 594\n",
            "plastic 482\n",
            "trash 137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(df['target'])\n",
        "# check https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
        "#y"
      ],
      "metadata": {
        "id": "YGlSEZ5O3pkf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label"
      ],
      "metadata": {
        "id": "nZ_iIcFRNue7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "data = np.empty((n, 224, 224, 3))"
      ],
      "metadata": {
        "id": "Y0IiAVMPNZF9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pythontutorials.eu/deep-learning/transfer-learning/"
      ],
      "metadata": {
        "id": "g5xlAJuoOle1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "\n",
        "for im in X:\n",
        "    im = preprocess_input(im)\n",
        "    im = resize(im, output_shape=(224, 224))\n",
        "    data[i] = im"
      ],
      "metadata": {
        "id": "VVRS0r0UNzw8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N7fPiisPnkF",
        "outputId": "ca863e8a-1221-4b58-f6fc-043af1a159dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2527"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUW3uDgsU5I2",
        "outputId": "872f1897-5d12-4fdd-fddf-51271ccb5970"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "m = len(tipos)\n",
        "\n",
        "'''\n",
        "labels_tf = np.empty(n, dtype=int)\n",
        "for idx, yi in enumerate(label):\n",
        "  labels_tf[idx] = yi\n",
        "'''\n",
        "idx = 0\n",
        "labels_tf = np.empty([n,m], dtype=int)\n",
        "for yi in y.values:\n",
        "  labels_tf[idx] = yi\n",
        "  idx = idx + 1\n",
        "\n"
      ],
      "metadata": {
        "id": "rcgv-joQO61M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check https://keras.io/api/applications/#mobilenetv2"
      ],
      "metadata": {
        "id": "F2zfestGaubO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "D = len(tipos)\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(D, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "ice3PlM0aBam"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "#model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# train the model on the new data for a few epochs\n",
        "model.fit(x=data, y=labels_tf, epochs=20, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2f2sL8Ca_C-",
        "outputId": "d7f85ccc-c90d-4f77-c42b-4b2dec95c5ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "79/79 - 14s - loss: 1.7902 - accuracy: 0.1820 - 14s/epoch - 172ms/step\n",
            "Epoch 2/20\n",
            "79/79 - 5s - loss: 1.7461 - accuracy: 0.2078 - 5s/epoch - 69ms/step\n",
            "Epoch 3/20\n",
            "79/79 - 5s - loss: 1.7319 - accuracy: 0.2125 - 5s/epoch - 69ms/step\n",
            "Epoch 4/20\n",
            "79/79 - 5s - loss: 1.7301 - accuracy: 0.2236 - 5s/epoch - 69ms/step\n",
            "Epoch 5/20\n",
            "79/79 - 6s - loss: 1.7283 - accuracy: 0.2311 - 6s/epoch - 70ms/step\n",
            "Epoch 6/20\n",
            "79/79 - 6s - loss: 1.7284 - accuracy: 0.2252 - 6s/epoch - 70ms/step\n",
            "Epoch 7/20\n",
            "79/79 - 6s - loss: 1.7292 - accuracy: 0.2307 - 6s/epoch - 72ms/step\n",
            "Epoch 8/20\n",
            "79/79 - 6s - loss: 1.7265 - accuracy: 0.2355 - 6s/epoch - 70ms/step\n",
            "Epoch 9/20\n",
            "79/79 - 6s - loss: 1.7268 - accuracy: 0.2315 - 6s/epoch - 70ms/step\n",
            "Epoch 10/20\n",
            "79/79 - 6s - loss: 1.7280 - accuracy: 0.2355 - 6s/epoch - 71ms/step\n",
            "Epoch 11/20\n",
            "79/79 - 6s - loss: 1.7270 - accuracy: 0.2355 - 6s/epoch - 71ms/step\n",
            "Epoch 12/20\n",
            "79/79 - 6s - loss: 1.7270 - accuracy: 0.2355 - 6s/epoch - 70ms/step\n",
            "Epoch 13/20\n",
            "79/79 - 6s - loss: 1.7263 - accuracy: 0.2355 - 6s/epoch - 70ms/step\n",
            "Epoch 14/20\n",
            "79/79 - 6s - loss: 1.7253 - accuracy: 0.2355 - 6s/epoch - 70ms/step\n",
            "Epoch 15/20\n",
            "79/79 - 5s - loss: 1.7251 - accuracy: 0.2287 - 5s/epoch - 69ms/step\n",
            "Epoch 16/20\n",
            "79/79 - 5s - loss: 1.7279 - accuracy: 0.2355 - 5s/epoch - 70ms/step\n",
            "Epoch 17/20\n",
            "79/79 - 5s - loss: 1.7253 - accuracy: 0.2355 - 5s/epoch - 70ms/step\n",
            "Epoch 18/20\n",
            "79/79 - 5s - loss: 1.7260 - accuracy: 0.2355 - 5s/epoch - 69ms/step\n",
            "Epoch 19/20\n",
            "79/79 - 6s - loss: 1.7245 - accuracy: 0.2355 - 6s/epoch - 70ms/step\n",
            "Epoch 20/20\n",
            "79/79 - 5s - loss: 1.7256 - accuracy: 0.2355 - 5s/epoch - 70ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f052038d450>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}