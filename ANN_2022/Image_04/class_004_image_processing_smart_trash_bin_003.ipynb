{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/wsHhWRuOMrsv5TuFv2I6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/ANN/blob/master/ANN_2022/Image_04/class_004_image_processing_smart_trash_bin_003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.feature\n",
        "from string import digits\n",
        "import seaborn as sns\n",
        "import skimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "7wNxYQBaKVJQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "JNNoeVHgb9WL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea3bxyjq-kcq",
        "outputId": "d657d57e-3cce-4dae-8b7a-43f82559e948"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX\n",
            "To: /content/trash_nov_22_2018.zip\n",
            "100% 42.8M/42.8M [00:00<00:00, 63.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE='trash_nov_22_2018.zip'"
      ],
      "metadata": {
        "id": "oyLilZ2l-loH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive = zipfile.ZipFile('trash_nov_22_2018.zip', 'r')\n",
        "archive.extractall()"
      ],
      "metadata": {
        "id": "XwXGEOlF_K1c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_name=[]\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "        img_name.append(name)"
      ],
      "metadata": {
        "id": "cs5xKcmpAgOA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Img_Size = 200\n",
        "ref = 'jpg'\n",
        "notref = 'met'"
      ],
      "metadata": {
        "id": "PVPFW06o_kw8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= []  \n",
        "Y =[]\n",
        "n = len(img_name)\n",
        "i = 0\n",
        "for i in range(n):\n",
        "  name = img_name[i]\n",
        "  if(ref in name):\n",
        "    Y.append(name)\n",
        "    img = cv2.imread(name)\n",
        "    resized = cv2.resize(img, (Img_Size,Img_Size))\n",
        "    X.append(resized)\n",
        "m = len(Y)\n",
        "print(n,m)"
      ],
      "metadata": {
        "id": "lAOB3uC3JG2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08aa817-1423-4d08-e8ff-506fca1d3e1c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2527 2527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "tipos = []\n",
        "selected = 'find'\n",
        "for x in img_name:\n",
        "  result =''.join([i for i in x[:-4] if not i.isdigit()])\n",
        "  if(result != selected):\n",
        "    selected = result\n",
        "    tipos.append(selected)\n"
      ],
      "metadata": {
        "id": "5Kh0R80ndBQ0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label =[]\n",
        "for name in img_name:\n",
        "  for idx, x in enumerate(tipos):\n",
        "    if(x in name):\n",
        "      label.append(idx)"
      ],
      "metadata": {
        "id": "MejkwNSX1kOi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(label,columns=['target'])"
      ],
      "metadata": {
        "id": "GyKMP7gCScy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6): \n",
        "  df_plot= df[(df[\"target\"] == i)]\n",
        "  n= df_plot.shape[0]\n",
        "  print(tipos[i],n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CDIVizOZXv",
        "outputId": "a26dd2ca-bd34-4aae-886a-7efc61cc2089"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard 403\n",
            "glass 501\n",
            "metal 410\n",
            "paper 594\n",
            "plastic 482\n",
            "trash 137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(df['target'])\n",
        "# check https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YGlSEZ5O3pkf",
        "outputId": "5cda4d7e-1916-467a-895a-8242d6380c3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0  1  2  3  4  5\n",
              "0     1  0  0  0  0  0\n",
              "1     1  0  0  0  0  0\n",
              "2     1  0  0  0  0  0\n",
              "3     1  0  0  0  0  0\n",
              "4     1  0  0  0  0  0\n",
              "...  .. .. .. .. .. ..\n",
              "2522  0  0  0  0  0  1\n",
              "2523  0  0  0  0  0  1\n",
              "2524  0  0  0  0  0  1\n",
              "2525  0  0  0  0  0  1\n",
              "2526  0  0  0  0  0  1\n",
              "\n",
              "[2527 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6016df2-769c-48a7-9282-5f7ac4b71b2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2522</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2523</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2524</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2525</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2526</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2527 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6016df2-769c-48a7-9282-5f7ac4b71b2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6016df2-769c-48a7-9282-5f7ac4b71b2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6016df2-769c-48a7-9282-5f7ac4b71b2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_SIZE = len(img_name)\n",
        "Ind = range(DATASET_SIZE)\n",
        "Ind_train, Ind_test= train_test_split(Ind,test_size=0.20,stratify=label, shuffle=True, random_state=3)"
      ],
      "metadata": {
        "id": "vk_QGYQCE_b6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "X_train=X[Ind_train]\n",
        "X_test = X[Ind_test]\n",
        "y_train=y.iloc[Ind_train,:]\n",
        "y_test = y.iloc[Ind_test,:]"
      ],
      "metadata": {
        "id": "g8ZTu5WRZXkF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(-1, Img_Size, Img_Size, 3) / 255.0\n",
        "X_test = X_test.reshape(-1, Img_Size, Img_Size, 3) / 255.0"
      ],
      "metadata": {
        "id": "p0FNK5SZabVD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn check\n",
        "# https://www.ibm.com/cloud/learn/convolutional-neural-networks\n",
        "# https://www.tensorflow.org/tutorials/images/cnn"
      ],
      "metadata": {
        "id": "VrPYTRGRdQSM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = y.shape[1]\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "# make the CNN\n",
        "# model.add(Input(shape=(28, 28, 1)))\n",
        "model.add(Conv2D(input_shape=(Img_Size, Img_Size, 3), filters=32, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=80))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=K))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "metadata": {
        "id": "wps7QCcOE6jF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ny8Q7RgPFo6q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gives us back a <keras.callbacks.History object at 0x112e61a90>\n",
        "r = model.fit(X_train, y_train, epochs=1000, batch_size=64)\n",
        "print(\"Returned:\", r)"
      ],
      "metadata": {
        "id": "RA8D90Y_asjm",
        "outputId": "8bf09c5b-cb09-44e5-f014-27ed2de10680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "32/32 [==============================] - 15s 149ms/step - loss: 3.8444 - accuracy: 0.2143\n",
            "Epoch 2/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.7186 - accuracy: 0.2746\n",
            "Epoch 3/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.6813 - accuracy: 0.2677\n",
            "Epoch 4/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.6092 - accuracy: 0.3028\n",
            "Epoch 5/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.5709 - accuracy: 0.3286\n",
            "Epoch 6/1000\n",
            "32/32 [==============================] - 4s 124ms/step - loss: 1.5588 - accuracy: 0.3380\n",
            "Epoch 7/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.5020 - accuracy: 0.4008\n",
            "Epoch 8/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.4840 - accuracy: 0.4142\n",
            "Epoch 9/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.4163 - accuracy: 0.4102\n",
            "Epoch 10/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.4135 - accuracy: 0.4161\n",
            "Epoch 11/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.3946 - accuracy: 0.4240\n",
            "Epoch 12/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.3922 - accuracy: 0.4285\n",
            "Epoch 13/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.3812 - accuracy: 0.4186\n",
            "Epoch 14/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.4104 - accuracy: 0.3968\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.3450 - accuracy: 0.4305\n",
            "Epoch 16/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 1.3152 - accuracy: 0.4270\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.3149 - accuracy: 0.4216\n",
            "Epoch 18/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2554 - accuracy: 0.4433\n",
            "Epoch 19/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.2566 - accuracy: 0.4270\n",
            "Epoch 20/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2559 - accuracy: 0.4404\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2604 - accuracy: 0.4290\n",
            "Epoch 22/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2390 - accuracy: 0.4424\n",
            "Epoch 23/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.2505 - accuracy: 0.4389\n",
            "Epoch 24/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.2533 - accuracy: 0.4567\n",
            "Epoch 25/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2508 - accuracy: 0.4473\n",
            "Epoch 26/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2190 - accuracy: 0.4617\n",
            "Epoch 27/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1903 - accuracy: 0.4607\n",
            "Epoch 28/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.2134 - accuracy: 0.4597\n",
            "Epoch 29/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.2114 - accuracy: 0.4874\n",
            "Epoch 30/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.1843 - accuracy: 0.4715\n",
            "Epoch 31/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.1485 - accuracy: 0.4923\n",
            "Epoch 32/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1729 - accuracy: 0.4869\n",
            "Epoch 33/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1821 - accuracy: 0.4834\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.1694 - accuracy: 0.5032\n",
            "Epoch 35/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1713 - accuracy: 0.5032\n",
            "Epoch 36/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1659 - accuracy: 0.4958\n",
            "Epoch 37/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.1042 - accuracy: 0.5339\n",
            "Epoch 38/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1398 - accuracy: 0.5309\n",
            "Epoch 39/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0971 - accuracy: 0.5359\n",
            "Epoch 40/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1045 - accuracy: 0.5349\n",
            "Epoch 41/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.1189 - accuracy: 0.5265\n",
            "Epoch 42/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.1115 - accuracy: 0.5324\n",
            "Epoch 43/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.0837 - accuracy: 0.5398\n",
            "Epoch 44/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.0743 - accuracy: 0.5606\n",
            "Epoch 45/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0775 - accuracy: 0.5522\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0350 - accuracy: 0.5789\n",
            "Epoch 47/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.0901 - accuracy: 0.5557\n",
            "Epoch 48/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.0715 - accuracy: 0.5685\n",
            "Epoch 49/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0535 - accuracy: 0.5675\n",
            "Epoch 50/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0307 - accuracy: 0.5784\n",
            "Epoch 51/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9848 - accuracy: 0.6042\n",
            "Epoch 52/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.0059 - accuracy: 0.5933\n",
            "Epoch 53/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 1.0254 - accuracy: 0.5903\n",
            "Epoch 54/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0128 - accuracy: 0.6032\n",
            "Epoch 55/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0100 - accuracy: 0.6032\n",
            "Epoch 56/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9963 - accuracy: 0.6195\n",
            "Epoch 57/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0080 - accuracy: 0.6042\n",
            "Epoch 58/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0049 - accuracy: 0.6101\n",
            "Epoch 59/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 1.0147 - accuracy: 0.6165\n",
            "Epoch 60/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9483 - accuracy: 0.6428\n",
            "Epoch 61/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9607 - accuracy: 0.6408\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9804 - accuracy: 0.6264\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9668 - accuracy: 0.6314\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9793 - accuracy: 0.6507\n",
            "Epoch 65/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9683 - accuracy: 0.6294\n",
            "Epoch 66/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 1.0063 - accuracy: 0.6071\n",
            "Epoch 67/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9412 - accuracy: 0.6447\n",
            "Epoch 68/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.9363 - accuracy: 0.6566\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9858 - accuracy: 0.6358\n",
            "Epoch 70/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9415 - accuracy: 0.6556\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9245 - accuracy: 0.6749\n",
            "Epoch 72/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9276 - accuracy: 0.6714\n",
            "Epoch 73/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9515 - accuracy: 0.6571\n",
            "Epoch 74/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9705 - accuracy: 0.6418\n",
            "Epoch 75/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9689 - accuracy: 0.6502\n",
            "Epoch 76/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9608 - accuracy: 0.6467\n",
            "Epoch 77/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9711 - accuracy: 0.6477\n",
            "Epoch 78/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9579 - accuracy: 0.6566\n",
            "Epoch 79/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9657 - accuracy: 0.6418\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.9621 - accuracy: 0.6591\n",
            "Epoch 81/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9271 - accuracy: 0.6655\n",
            "Epoch 82/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9287 - accuracy: 0.6729\n",
            "Epoch 83/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8981 - accuracy: 0.6868\n",
            "Epoch 84/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8935 - accuracy: 0.6878\n",
            "Epoch 85/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9366 - accuracy: 0.6645\n",
            "Epoch 86/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9714 - accuracy: 0.6517\n",
            "Epoch 87/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9479 - accuracy: 0.6655\n",
            "Epoch 88/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9314 - accuracy: 0.6734\n",
            "Epoch 89/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.9031 - accuracy: 0.6868\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9388 - accuracy: 0.6680\n",
            "Epoch 91/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8919 - accuracy: 0.6883\n",
            "Epoch 92/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9103 - accuracy: 0.6818\n",
            "Epoch 93/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8812 - accuracy: 0.7001\n",
            "Epoch 94/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9037 - accuracy: 0.6843\n",
            "Epoch 95/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8742 - accuracy: 0.7026\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.9092 - accuracy: 0.6809\n",
            "Epoch 97/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9253 - accuracy: 0.6774\n",
            "Epoch 98/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8799 - accuracy: 0.6957\n",
            "Epoch 99/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8829 - accuracy: 0.6977\n",
            "Epoch 100/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8935 - accuracy: 0.6937\n",
            "Epoch 101/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9144 - accuracy: 0.6863\n",
            "Epoch 102/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8399 - accuracy: 0.7091\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8775 - accuracy: 0.7006\n",
            "Epoch 104/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8650 - accuracy: 0.7081\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8915 - accuracy: 0.6962\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8561 - accuracy: 0.7105\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8816 - accuracy: 0.7016\n",
            "Epoch 108/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8490 - accuracy: 0.7194\n",
            "Epoch 109/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8619 - accuracy: 0.7026\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8676 - accuracy: 0.7110\n",
            "Epoch 111/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8721 - accuracy: 0.7026\n",
            "Epoch 112/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8627 - accuracy: 0.7071\n",
            "Epoch 113/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8808 - accuracy: 0.7041\n",
            "Epoch 114/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9036 - accuracy: 0.6922\n",
            "Epoch 115/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8910 - accuracy: 0.6932\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8789 - accuracy: 0.6937\n",
            "Epoch 117/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8537 - accuracy: 0.7125\n",
            "Epoch 118/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8775 - accuracy: 0.6942\n",
            "Epoch 119/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8847 - accuracy: 0.6967\n",
            "Epoch 120/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8480 - accuracy: 0.7135\n",
            "Epoch 121/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8640 - accuracy: 0.7041\n",
            "Epoch 122/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9094 - accuracy: 0.6937\n",
            "Epoch 123/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9054 - accuracy: 0.6878\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8279 - accuracy: 0.7120\n",
            "Epoch 125/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8462 - accuracy: 0.7180\n",
            "Epoch 126/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8709 - accuracy: 0.7076\n",
            "Epoch 127/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8807 - accuracy: 0.6997\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8617 - accuracy: 0.7170\n",
            "Epoch 129/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8524 - accuracy: 0.7095\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8835 - accuracy: 0.7091\n",
            "Epoch 131/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8406 - accuracy: 0.7175\n",
            "Epoch 132/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8474 - accuracy: 0.7150\n",
            "Epoch 133/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8347 - accuracy: 0.7185\n",
            "Epoch 134/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.8540 - accuracy: 0.7115\n",
            "Epoch 135/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8565 - accuracy: 0.7130\n",
            "Epoch 136/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8493 - accuracy: 0.7209\n",
            "Epoch 137/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8293 - accuracy: 0.7249\n",
            "Epoch 138/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8312 - accuracy: 0.7234\n",
            "Epoch 139/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8591 - accuracy: 0.7095\n",
            "Epoch 140/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8726 - accuracy: 0.6977\n",
            "Epoch 141/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8744 - accuracy: 0.7066\n",
            "Epoch 142/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8412 - accuracy: 0.7185\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8334 - accuracy: 0.7219\n",
            "Epoch 144/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8275 - accuracy: 0.7303\n",
            "Epoch 145/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8294 - accuracy: 0.7224\n",
            "Epoch 146/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8287 - accuracy: 0.7244\n",
            "Epoch 147/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8378 - accuracy: 0.7239\n",
            "Epoch 148/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8699 - accuracy: 0.7016\n",
            "Epoch 149/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8912 - accuracy: 0.6952\n",
            "Epoch 150/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8422 - accuracy: 0.7135\n",
            "Epoch 151/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8345 - accuracy: 0.7274\n",
            "Epoch 152/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8519 - accuracy: 0.7130\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8343 - accuracy: 0.7279\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8538 - accuracy: 0.7175\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8497 - accuracy: 0.7110\n",
            "Epoch 156/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8696 - accuracy: 0.7046\n",
            "Epoch 157/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8912 - accuracy: 0.7001\n",
            "Epoch 158/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8515 - accuracy: 0.7125\n",
            "Epoch 159/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8525 - accuracy: 0.7105\n",
            "Epoch 160/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8665 - accuracy: 0.6937\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8309 - accuracy: 0.7234\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8083 - accuracy: 0.7308\n",
            "Epoch 163/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8142 - accuracy: 0.7254\n",
            "Epoch 164/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8473 - accuracy: 0.7150\n",
            "Epoch 165/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8243 - accuracy: 0.7185\n",
            "Epoch 166/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8229 - accuracy: 0.7264\n",
            "Epoch 167/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8544 - accuracy: 0.7165\n",
            "Epoch 168/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8210 - accuracy: 0.7199\n",
            "Epoch 169/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8347 - accuracy: 0.7239\n",
            "Epoch 170/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8690 - accuracy: 0.7056\n",
            "Epoch 171/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8297 - accuracy: 0.7209\n",
            "Epoch 172/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8361 - accuracy: 0.7091\n",
            "Epoch 173/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8378 - accuracy: 0.7214\n",
            "Epoch 174/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8127 - accuracy: 0.7303\n",
            "Epoch 175/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7817 - accuracy: 0.7417\n",
            "Epoch 176/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8048 - accuracy: 0.7368\n",
            "Epoch 177/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7992 - accuracy: 0.7254\n",
            "Epoch 178/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8297 - accuracy: 0.7140\n",
            "Epoch 179/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8262 - accuracy: 0.7214\n",
            "Epoch 180/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.8322 - accuracy: 0.7229\n",
            "Epoch 181/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7987 - accuracy: 0.7427\n",
            "Epoch 182/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8459 - accuracy: 0.7091\n",
            "Epoch 183/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8095 - accuracy: 0.7284\n",
            "Epoch 184/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8017 - accuracy: 0.7343\n",
            "Epoch 185/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8306 - accuracy: 0.7254\n",
            "Epoch 186/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8297 - accuracy: 0.7209\n",
            "Epoch 187/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7855 - accuracy: 0.7387\n",
            "Epoch 188/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8076 - accuracy: 0.7358\n",
            "Epoch 189/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8027 - accuracy: 0.7279\n",
            "Epoch 190/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8605 - accuracy: 0.7155\n",
            "Epoch 191/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8277 - accuracy: 0.7308\n",
            "Epoch 192/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.9056 - accuracy: 0.7001\n",
            "Epoch 193/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8555 - accuracy: 0.7056\n",
            "Epoch 194/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8369 - accuracy: 0.7165\n",
            "Epoch 195/1000\n",
            "32/32 [==============================] - 4s 132ms/step - loss: 0.8061 - accuracy: 0.7284\n",
            "Epoch 196/1000\n",
            "32/32 [==============================] - 4s 134ms/step - loss: 0.8204 - accuracy: 0.7259\n",
            "Epoch 197/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7909 - accuracy: 0.7328\n",
            "Epoch 198/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8032 - accuracy: 0.7308\n",
            "Epoch 199/1000\n",
            "32/32 [==============================] - 4s 135ms/step - loss: 0.8081 - accuracy: 0.7288\n",
            "Epoch 200/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8092 - accuracy: 0.7229\n",
            "Epoch 201/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7594 - accuracy: 0.7511\n",
            "Epoch 202/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8337 - accuracy: 0.7234\n",
            "Epoch 203/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7945 - accuracy: 0.7373\n",
            "Epoch 204/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8006 - accuracy: 0.7293\n",
            "Epoch 205/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8065 - accuracy: 0.7204\n",
            "Epoch 206/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8263 - accuracy: 0.7194\n",
            "Epoch 207/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7772 - accuracy: 0.7318\n",
            "Epoch 208/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8138 - accuracy: 0.7185\n",
            "Epoch 209/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7912 - accuracy: 0.7284\n",
            "Epoch 210/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8210 - accuracy: 0.7224\n",
            "Epoch 211/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8510 - accuracy: 0.7061\n",
            "Epoch 212/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.8060 - accuracy: 0.7204\n",
            "Epoch 213/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8135 - accuracy: 0.7303\n",
            "Epoch 214/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8364 - accuracy: 0.7115\n",
            "Epoch 215/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7878 - accuracy: 0.7387\n",
            "Epoch 216/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7906 - accuracy: 0.7259\n",
            "Epoch 217/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7910 - accuracy: 0.7333\n",
            "Epoch 218/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7856 - accuracy: 0.7348\n",
            "Epoch 219/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7983 - accuracy: 0.7160\n",
            "Epoch 220/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8211 - accuracy: 0.7244\n",
            "Epoch 221/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.8194 - accuracy: 0.7219\n",
            "Epoch 222/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8058 - accuracy: 0.7194\n",
            "Epoch 223/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8171 - accuracy: 0.7219\n",
            "Epoch 224/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8048 - accuracy: 0.7279\n",
            "Epoch 225/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.8381 - accuracy: 0.7194\n",
            "Epoch 226/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7950 - accuracy: 0.7353\n",
            "Epoch 227/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7937 - accuracy: 0.7274\n",
            "Epoch 228/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7673 - accuracy: 0.7328\n",
            "Epoch 229/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8345 - accuracy: 0.7120\n",
            "Epoch 230/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8268 - accuracy: 0.7145\n",
            "Epoch 231/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8335 - accuracy: 0.7066\n",
            "Epoch 232/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8005 - accuracy: 0.7234\n",
            "Epoch 233/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8290 - accuracy: 0.7130\n",
            "Epoch 234/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7964 - accuracy: 0.7234\n",
            "Epoch 235/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8592 - accuracy: 0.7120\n",
            "Epoch 236/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8324 - accuracy: 0.7095\n",
            "Epoch 237/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7821 - accuracy: 0.7333\n",
            "Epoch 238/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8000 - accuracy: 0.7279\n",
            "Epoch 239/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7978 - accuracy: 0.7298\n",
            "Epoch 240/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8250 - accuracy: 0.7130\n",
            "Epoch 241/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7737 - accuracy: 0.7353\n",
            "Epoch 242/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7742 - accuracy: 0.7358\n",
            "Epoch 243/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7561 - accuracy: 0.7442\n",
            "Epoch 244/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7630 - accuracy: 0.7382\n",
            "Epoch 245/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7836 - accuracy: 0.7338\n",
            "Epoch 246/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7945 - accuracy: 0.7254\n",
            "Epoch 247/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7791 - accuracy: 0.7343\n",
            "Epoch 248/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7454 - accuracy: 0.7462\n",
            "Epoch 249/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7873 - accuracy: 0.7298\n",
            "Epoch 250/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8432 - accuracy: 0.7086\n",
            "Epoch 251/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8047 - accuracy: 0.7214\n",
            "Epoch 252/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8133 - accuracy: 0.7259\n",
            "Epoch 253/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7722 - accuracy: 0.7363\n",
            "Epoch 254/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7608 - accuracy: 0.7412\n",
            "Epoch 255/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7914 - accuracy: 0.7190\n",
            "Epoch 256/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7783 - accuracy: 0.7328\n",
            "Epoch 257/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8043 - accuracy: 0.7214\n",
            "Epoch 258/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8534 - accuracy: 0.6982\n",
            "Epoch 259/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8258 - accuracy: 0.7150\n",
            "Epoch 260/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7854 - accuracy: 0.7293\n",
            "Epoch 261/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7789 - accuracy: 0.7254\n",
            "Epoch 262/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7723 - accuracy: 0.7373\n",
            "Epoch 263/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7880 - accuracy: 0.7293\n",
            "Epoch 264/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7960 - accuracy: 0.7224\n",
            "Epoch 265/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8082 - accuracy: 0.7214\n",
            "Epoch 266/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8018 - accuracy: 0.7229\n",
            "Epoch 267/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8144 - accuracy: 0.7224\n",
            "Epoch 268/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7586 - accuracy: 0.7402\n",
            "Epoch 269/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7703 - accuracy: 0.7427\n",
            "Epoch 270/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7850 - accuracy: 0.7254\n",
            "Epoch 271/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7983 - accuracy: 0.7234\n",
            "Epoch 272/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7934 - accuracy: 0.7288\n",
            "Epoch 273/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7787 - accuracy: 0.7264\n",
            "Epoch 274/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8066 - accuracy: 0.7209\n",
            "Epoch 275/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7832 - accuracy: 0.7323\n",
            "Epoch 276/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7352 - accuracy: 0.7432\n",
            "Epoch 277/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7964 - accuracy: 0.7180\n",
            "Epoch 278/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7865 - accuracy: 0.7274\n",
            "Epoch 279/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8046 - accuracy: 0.7244\n",
            "Epoch 280/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8015 - accuracy: 0.7219\n",
            "Epoch 281/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7592 - accuracy: 0.7373\n",
            "Epoch 282/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7463 - accuracy: 0.7442\n",
            "Epoch 283/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7272 - accuracy: 0.7501\n",
            "Epoch 284/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7338 - accuracy: 0.7516\n",
            "Epoch 285/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7771 - accuracy: 0.7279\n",
            "Epoch 286/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7704 - accuracy: 0.7259\n",
            "Epoch 287/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7644 - accuracy: 0.7279\n",
            "Epoch 288/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8385 - accuracy: 0.7199\n",
            "Epoch 289/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7865 - accuracy: 0.7318\n",
            "Epoch 290/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7727 - accuracy: 0.7259\n",
            "Epoch 291/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7630 - accuracy: 0.7313\n",
            "Epoch 292/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7707 - accuracy: 0.7402\n",
            "Epoch 293/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7856 - accuracy: 0.7264\n",
            "Epoch 294/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7988 - accuracy: 0.7308\n",
            "Epoch 295/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7700 - accuracy: 0.7298\n",
            "Epoch 296/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7910 - accuracy: 0.7249\n",
            "Epoch 297/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7884 - accuracy: 0.7214\n",
            "Epoch 298/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7878 - accuracy: 0.7244\n",
            "Epoch 299/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7861 - accuracy: 0.7254\n",
            "Epoch 300/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7720 - accuracy: 0.7353\n",
            "Epoch 301/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7807 - accuracy: 0.7264\n",
            "Epoch 302/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7758 - accuracy: 0.7288\n",
            "Epoch 303/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7575 - accuracy: 0.7402\n",
            "Epoch 304/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7897 - accuracy: 0.7219\n",
            "Epoch 305/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7788 - accuracy: 0.7338\n",
            "Epoch 306/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8290 - accuracy: 0.7046\n",
            "Epoch 307/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7813 - accuracy: 0.7328\n",
            "Epoch 308/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8211 - accuracy: 0.7170\n",
            "Epoch 309/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8377 - accuracy: 0.7081\n",
            "Epoch 310/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8033 - accuracy: 0.7214\n",
            "Epoch 311/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7546 - accuracy: 0.7358\n",
            "Epoch 312/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7595 - accuracy: 0.7373\n",
            "Epoch 313/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7353 - accuracy: 0.7457\n",
            "Epoch 314/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7684 - accuracy: 0.7358\n",
            "Epoch 315/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7693 - accuracy: 0.7288\n",
            "Epoch 316/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7221 - accuracy: 0.7496\n",
            "Epoch 317/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7787 - accuracy: 0.7234\n",
            "Epoch 318/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7676 - accuracy: 0.7318\n",
            "Epoch 319/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7823 - accuracy: 0.7279\n",
            "Epoch 320/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7778 - accuracy: 0.7313\n",
            "Epoch 321/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7665 - accuracy: 0.7308\n",
            "Epoch 322/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7627 - accuracy: 0.7358\n",
            "Epoch 323/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7774 - accuracy: 0.7323\n",
            "Epoch 324/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7627 - accuracy: 0.7254\n",
            "Epoch 325/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7582 - accuracy: 0.7313\n",
            "Epoch 326/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8105 - accuracy: 0.7239\n",
            "Epoch 327/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7502 - accuracy: 0.7382\n",
            "Epoch 328/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7478 - accuracy: 0.7447\n",
            "Epoch 329/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7790 - accuracy: 0.7348\n",
            "Epoch 330/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7710 - accuracy: 0.7373\n",
            "Epoch 331/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7687 - accuracy: 0.7338\n",
            "Epoch 332/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7959 - accuracy: 0.7249\n",
            "Epoch 333/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7956 - accuracy: 0.7298\n",
            "Epoch 334/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7768 - accuracy: 0.7303\n",
            "Epoch 335/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7307 - accuracy: 0.7506\n",
            "Epoch 336/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7638 - accuracy: 0.7288\n",
            "Epoch 337/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7555 - accuracy: 0.7531\n",
            "Epoch 338/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7735 - accuracy: 0.7338\n",
            "Epoch 339/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7753 - accuracy: 0.7303\n",
            "Epoch 340/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7987 - accuracy: 0.7199\n",
            "Epoch 341/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7698 - accuracy: 0.7343\n",
            "Epoch 342/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7647 - accuracy: 0.7363\n",
            "Epoch 343/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7722 - accuracy: 0.7318\n",
            "Epoch 344/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7574 - accuracy: 0.7338\n",
            "Epoch 345/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7455 - accuracy: 0.7397\n",
            "Epoch 346/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7505 - accuracy: 0.7323\n",
            "Epoch 347/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7459 - accuracy: 0.7402\n",
            "Epoch 348/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7107 - accuracy: 0.7476\n",
            "Epoch 349/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7133 - accuracy: 0.7536\n",
            "Epoch 350/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7547 - accuracy: 0.7397\n",
            "Epoch 351/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7515 - accuracy: 0.7333\n",
            "Epoch 352/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7574 - accuracy: 0.7402\n",
            "Epoch 353/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7253 - accuracy: 0.7526\n",
            "Epoch 354/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7596 - accuracy: 0.7353\n",
            "Epoch 355/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7722 - accuracy: 0.7244\n",
            "Epoch 356/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7855 - accuracy: 0.7288\n",
            "Epoch 357/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7448 - accuracy: 0.7442\n",
            "Epoch 358/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8057 - accuracy: 0.7145\n",
            "Epoch 359/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7600 - accuracy: 0.7288\n",
            "Epoch 360/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7910 - accuracy: 0.7279\n",
            "Epoch 361/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7907 - accuracy: 0.7274\n",
            "Epoch 362/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7404 - accuracy: 0.7447\n",
            "Epoch 363/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7662 - accuracy: 0.7333\n",
            "Epoch 364/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7352 - accuracy: 0.7462\n",
            "Epoch 365/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7595 - accuracy: 0.7343\n",
            "Epoch 366/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7392 - accuracy: 0.7501\n",
            "Epoch 367/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7903 - accuracy: 0.7249\n",
            "Epoch 368/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7425 - accuracy: 0.7417\n",
            "Epoch 369/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7347 - accuracy: 0.7368\n",
            "Epoch 370/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7393 - accuracy: 0.7472\n",
            "Epoch 371/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7417 - accuracy: 0.7501\n",
            "Epoch 372/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7471 - accuracy: 0.7368\n",
            "Epoch 373/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7186 - accuracy: 0.7561\n",
            "Epoch 374/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7774 - accuracy: 0.7279\n",
            "Epoch 375/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7206 - accuracy: 0.7511\n",
            "Epoch 376/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7409 - accuracy: 0.7417\n",
            "Epoch 377/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7564 - accuracy: 0.7333\n",
            "Epoch 378/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7387 - accuracy: 0.7387\n",
            "Epoch 379/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7433 - accuracy: 0.7387\n",
            "Epoch 380/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7349 - accuracy: 0.7412\n",
            "Epoch 381/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7793 - accuracy: 0.7279\n",
            "Epoch 382/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7554 - accuracy: 0.7303\n",
            "Epoch 383/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7464 - accuracy: 0.7417\n",
            "Epoch 384/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7956 - accuracy: 0.7269\n",
            "Epoch 385/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7892 - accuracy: 0.7234\n",
            "Epoch 386/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7599 - accuracy: 0.7343\n",
            "Epoch 387/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.8123 - accuracy: 0.7105\n",
            "Epoch 388/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7504 - accuracy: 0.7373\n",
            "Epoch 389/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7427 - accuracy: 0.7417\n",
            "Epoch 390/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7939 - accuracy: 0.7214\n",
            "Epoch 391/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7705 - accuracy: 0.7274\n",
            "Epoch 392/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7383 - accuracy: 0.7368\n",
            "Epoch 393/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7228 - accuracy: 0.7536\n",
            "Epoch 394/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7624 - accuracy: 0.7264\n",
            "Epoch 395/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7752 - accuracy: 0.7402\n",
            "Epoch 396/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7713 - accuracy: 0.7274\n",
            "Epoch 397/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7834 - accuracy: 0.7135\n",
            "Epoch 398/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7631 - accuracy: 0.7378\n",
            "Epoch 399/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7393 - accuracy: 0.7417\n",
            "Epoch 400/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7700 - accuracy: 0.7387\n",
            "Epoch 401/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7820 - accuracy: 0.7234\n",
            "Epoch 402/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7363 - accuracy: 0.7432\n",
            "Epoch 403/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7344 - accuracy: 0.7476\n",
            "Epoch 404/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7354 - accuracy: 0.7407\n",
            "Epoch 405/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7240 - accuracy: 0.7496\n",
            "Epoch 406/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7407 - accuracy: 0.7392\n",
            "Epoch 407/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7433 - accuracy: 0.7363\n",
            "Epoch 408/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7450 - accuracy: 0.7402\n",
            "Epoch 409/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7728 - accuracy: 0.7264\n",
            "Epoch 410/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7974 - accuracy: 0.7269\n",
            "Epoch 411/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7569 - accuracy: 0.7338\n",
            "Epoch 412/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7884 - accuracy: 0.7199\n",
            "Epoch 413/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7615 - accuracy: 0.7402\n",
            "Epoch 414/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7760 - accuracy: 0.7284\n",
            "Epoch 415/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7318 - accuracy: 0.7452\n",
            "Epoch 416/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7435 - accuracy: 0.7427\n",
            "Epoch 417/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7532 - accuracy: 0.7363\n",
            "Epoch 418/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7139 - accuracy: 0.7472\n",
            "Epoch 419/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7344 - accuracy: 0.7462\n",
            "Epoch 420/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7383 - accuracy: 0.7486\n",
            "Epoch 421/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7336 - accuracy: 0.7387\n",
            "Epoch 422/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7339 - accuracy: 0.7407\n",
            "Epoch 423/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7314 - accuracy: 0.7486\n",
            "Epoch 424/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7006 - accuracy: 0.7575\n",
            "Epoch 425/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7221 - accuracy: 0.7437\n",
            "Epoch 426/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7047 - accuracy: 0.7575\n",
            "Epoch 427/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7564 - accuracy: 0.7363\n",
            "Epoch 428/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7464 - accuracy: 0.7467\n",
            "Epoch 429/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7217 - accuracy: 0.7422\n",
            "Epoch 430/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7293 - accuracy: 0.7486\n",
            "Epoch 431/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7541 - accuracy: 0.7387\n",
            "Epoch 432/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7655 - accuracy: 0.7373\n",
            "Epoch 433/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7578 - accuracy: 0.7308\n",
            "Epoch 434/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7390 - accuracy: 0.7447\n",
            "Epoch 435/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7399 - accuracy: 0.7407\n",
            "Epoch 436/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7546 - accuracy: 0.7338\n",
            "Epoch 437/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7173 - accuracy: 0.7521\n",
            "Epoch 438/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7590 - accuracy: 0.7387\n",
            "Epoch 439/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7213 - accuracy: 0.7476\n",
            "Epoch 440/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7490 - accuracy: 0.7387\n",
            "Epoch 441/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7393 - accuracy: 0.7412\n",
            "Epoch 442/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7438 - accuracy: 0.7378\n",
            "Epoch 443/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7763 - accuracy: 0.7343\n",
            "Epoch 444/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.8028 - accuracy: 0.7165\n",
            "Epoch 445/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7887 - accuracy: 0.7209\n",
            "Epoch 446/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7748 - accuracy: 0.7259\n",
            "Epoch 447/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7204 - accuracy: 0.7486\n",
            "Epoch 448/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7312 - accuracy: 0.7343\n",
            "Epoch 449/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7376 - accuracy: 0.7462\n",
            "Epoch 450/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7324 - accuracy: 0.7457\n",
            "Epoch 451/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7385 - accuracy: 0.7447\n",
            "Epoch 452/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7187 - accuracy: 0.7472\n",
            "Epoch 453/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7643 - accuracy: 0.7318\n",
            "Epoch 454/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7558 - accuracy: 0.7323\n",
            "Epoch 455/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7522 - accuracy: 0.7417\n",
            "Epoch 456/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7566 - accuracy: 0.7392\n",
            "Epoch 457/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7489 - accuracy: 0.7358\n",
            "Epoch 458/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7339 - accuracy: 0.7486\n",
            "Epoch 459/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7909 - accuracy: 0.7219\n",
            "Epoch 460/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7408 - accuracy: 0.7407\n",
            "Epoch 461/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7494 - accuracy: 0.7363\n",
            "Epoch 462/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7310 - accuracy: 0.7407\n",
            "Epoch 463/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7389 - accuracy: 0.7432\n",
            "Epoch 464/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7444 - accuracy: 0.7387\n",
            "Epoch 465/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7346 - accuracy: 0.7442\n",
            "Epoch 466/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7438 - accuracy: 0.7481\n",
            "Epoch 467/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7122 - accuracy: 0.7575\n",
            "Epoch 468/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7023 - accuracy: 0.7571\n",
            "Epoch 469/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7312 - accuracy: 0.7437\n",
            "Epoch 470/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7295 - accuracy: 0.7457\n",
            "Epoch 471/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7558 - accuracy: 0.7348\n",
            "Epoch 472/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7650 - accuracy: 0.7353\n",
            "Epoch 473/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7498 - accuracy: 0.7343\n",
            "Epoch 474/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7714 - accuracy: 0.7348\n",
            "Epoch 475/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7421 - accuracy: 0.7368\n",
            "Epoch 476/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7274 - accuracy: 0.7496\n",
            "Epoch 477/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7409 - accuracy: 0.7387\n",
            "Epoch 478/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7536 - accuracy: 0.7353\n",
            "Epoch 479/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7618 - accuracy: 0.7358\n",
            "Epoch 480/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7555 - accuracy: 0.7323\n",
            "Epoch 481/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7374 - accuracy: 0.7452\n",
            "Epoch 482/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7375 - accuracy: 0.7447\n",
            "Epoch 483/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7640 - accuracy: 0.7323\n",
            "Epoch 484/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7468 - accuracy: 0.7387\n",
            "Epoch 485/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7599 - accuracy: 0.7338\n",
            "Epoch 486/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7478 - accuracy: 0.7363\n",
            "Epoch 487/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7525 - accuracy: 0.7333\n",
            "Epoch 488/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7093 - accuracy: 0.7511\n",
            "Epoch 489/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7361 - accuracy: 0.7387\n",
            "Epoch 490/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7337 - accuracy: 0.7407\n",
            "Epoch 491/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7344 - accuracy: 0.7363\n",
            "Epoch 492/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7266 - accuracy: 0.7407\n",
            "Epoch 493/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7736 - accuracy: 0.7284\n",
            "Epoch 494/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7614 - accuracy: 0.7368\n",
            "Epoch 495/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7280 - accuracy: 0.7491\n",
            "Epoch 496/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7086 - accuracy: 0.7546\n",
            "Epoch 497/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7278 - accuracy: 0.7506\n",
            "Epoch 498/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7044 - accuracy: 0.7551\n",
            "Epoch 499/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7011 - accuracy: 0.7541\n",
            "Epoch 500/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7586 - accuracy: 0.7363\n",
            "Epoch 501/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6992 - accuracy: 0.7571\n",
            "Epoch 502/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6964 - accuracy: 0.7645\n",
            "Epoch 503/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7035 - accuracy: 0.7511\n",
            "Epoch 504/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7491 - accuracy: 0.7303\n",
            "Epoch 505/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7177 - accuracy: 0.7452\n",
            "Epoch 506/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7634 - accuracy: 0.7402\n",
            "Epoch 507/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7550 - accuracy: 0.7328\n",
            "Epoch 508/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7868 - accuracy: 0.7180\n",
            "Epoch 509/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7959 - accuracy: 0.7274\n",
            "Epoch 510/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.8091 - accuracy: 0.7165\n",
            "Epoch 511/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7643 - accuracy: 0.7338\n",
            "Epoch 512/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7616 - accuracy: 0.7303\n",
            "Epoch 513/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7727 - accuracy: 0.7264\n",
            "Epoch 514/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7547 - accuracy: 0.7318\n",
            "Epoch 515/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7525 - accuracy: 0.7328\n",
            "Epoch 516/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7110 - accuracy: 0.7521\n",
            "Epoch 517/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7207 - accuracy: 0.7467\n",
            "Epoch 518/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7348 - accuracy: 0.7491\n",
            "Epoch 519/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7941 - accuracy: 0.7229\n",
            "Epoch 520/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7369 - accuracy: 0.7387\n",
            "Epoch 521/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7416 - accuracy: 0.7382\n",
            "Epoch 522/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7119 - accuracy: 0.7526\n",
            "Epoch 523/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7276 - accuracy: 0.7392\n",
            "Epoch 524/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7433 - accuracy: 0.7412\n",
            "Epoch 525/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7440 - accuracy: 0.7318\n",
            "Epoch 526/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7778 - accuracy: 0.7343\n",
            "Epoch 527/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7569 - accuracy: 0.7348\n",
            "Epoch 528/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7349 - accuracy: 0.7402\n",
            "Epoch 529/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7251 - accuracy: 0.7506\n",
            "Epoch 530/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7392 - accuracy: 0.7432\n",
            "Epoch 531/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7149 - accuracy: 0.7516\n",
            "Epoch 532/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7553 - accuracy: 0.7382\n",
            "Epoch 533/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7230 - accuracy: 0.7462\n",
            "Epoch 534/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7324 - accuracy: 0.7467\n",
            "Epoch 535/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7500 - accuracy: 0.7392\n",
            "Epoch 536/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7474 - accuracy: 0.7353\n",
            "Epoch 537/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7400 - accuracy: 0.7373\n",
            "Epoch 538/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7290 - accuracy: 0.7432\n",
            "Epoch 539/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6831 - accuracy: 0.7571\n",
            "Epoch 540/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7243 - accuracy: 0.7491\n",
            "Epoch 541/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7082 - accuracy: 0.7566\n",
            "Epoch 542/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7360 - accuracy: 0.7417\n",
            "Epoch 543/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7139 - accuracy: 0.7511\n",
            "Epoch 544/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7326 - accuracy: 0.7457\n",
            "Epoch 545/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7410 - accuracy: 0.7472\n",
            "Epoch 546/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7247 - accuracy: 0.7432\n",
            "Epoch 547/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7276 - accuracy: 0.7481\n",
            "Epoch 548/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7570 - accuracy: 0.7298\n",
            "Epoch 549/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7268 - accuracy: 0.7407\n",
            "Epoch 550/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7380 - accuracy: 0.7392\n",
            "Epoch 551/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7677 - accuracy: 0.7348\n",
            "Epoch 552/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7230 - accuracy: 0.7511\n",
            "Epoch 553/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7608 - accuracy: 0.7363\n",
            "Epoch 554/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7243 - accuracy: 0.7511\n",
            "Epoch 555/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7366 - accuracy: 0.7447\n",
            "Epoch 556/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7215 - accuracy: 0.7575\n",
            "Epoch 557/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7253 - accuracy: 0.7392\n",
            "Epoch 558/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7573 - accuracy: 0.7363\n",
            "Epoch 559/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7170 - accuracy: 0.7452\n",
            "Epoch 560/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7442 - accuracy: 0.7323\n",
            "Epoch 561/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7288 - accuracy: 0.7437\n",
            "Epoch 562/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7515 - accuracy: 0.7298\n",
            "Epoch 563/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7293 - accuracy: 0.7481\n",
            "Epoch 564/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7227 - accuracy: 0.7486\n",
            "Epoch 565/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6858 - accuracy: 0.7590\n",
            "Epoch 566/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7873 - accuracy: 0.7199\n",
            "Epoch 567/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6720 - accuracy: 0.7679\n",
            "Epoch 568/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7372 - accuracy: 0.7462\n",
            "Epoch 569/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7212 - accuracy: 0.7452\n",
            "Epoch 570/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6925 - accuracy: 0.7501\n",
            "Epoch 571/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7274 - accuracy: 0.7486\n",
            "Epoch 572/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7245 - accuracy: 0.7481\n",
            "Epoch 573/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7437 - accuracy: 0.7437\n",
            "Epoch 574/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7314 - accuracy: 0.7328\n",
            "Epoch 575/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7538 - accuracy: 0.7323\n",
            "Epoch 576/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7325 - accuracy: 0.7437\n",
            "Epoch 577/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7602 - accuracy: 0.7382\n",
            "Epoch 578/1000\n",
            "32/32 [==============================] - 4s 132ms/step - loss: 0.7472 - accuracy: 0.7303\n",
            "Epoch 579/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7676 - accuracy: 0.7328\n",
            "Epoch 580/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7355 - accuracy: 0.7402\n",
            "Epoch 581/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7504 - accuracy: 0.7338\n",
            "Epoch 582/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7779 - accuracy: 0.7269\n",
            "Epoch 583/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6997 - accuracy: 0.7541\n",
            "Epoch 584/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7572 - accuracy: 0.7333\n",
            "Epoch 585/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7561 - accuracy: 0.7382\n",
            "Epoch 586/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7664 - accuracy: 0.7338\n",
            "Epoch 587/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7446 - accuracy: 0.7462\n",
            "Epoch 588/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7299 - accuracy: 0.7452\n",
            "Epoch 589/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7952 - accuracy: 0.7244\n",
            "Epoch 590/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7469 - accuracy: 0.7378\n",
            "Epoch 591/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7824 - accuracy: 0.7264\n",
            "Epoch 592/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7523 - accuracy: 0.7333\n",
            "Epoch 593/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7485 - accuracy: 0.7382\n",
            "Epoch 594/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7749 - accuracy: 0.7303\n",
            "Epoch 595/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7320 - accuracy: 0.7382\n",
            "Epoch 596/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7261 - accuracy: 0.7506\n",
            "Epoch 597/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7718 - accuracy: 0.7298\n",
            "Epoch 598/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7146 - accuracy: 0.7481\n",
            "Epoch 599/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7365 - accuracy: 0.7417\n",
            "Epoch 600/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7191 - accuracy: 0.7457\n",
            "Epoch 601/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7226 - accuracy: 0.7467\n",
            "Epoch 602/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7719 - accuracy: 0.7269\n",
            "Epoch 603/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7420 - accuracy: 0.7293\n",
            "Epoch 604/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7183 - accuracy: 0.7472\n",
            "Epoch 605/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7433 - accuracy: 0.7323\n",
            "Epoch 606/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6977 - accuracy: 0.7501\n",
            "Epoch 607/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7173 - accuracy: 0.7402\n",
            "Epoch 608/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7157 - accuracy: 0.7486\n",
            "Epoch 609/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7440 - accuracy: 0.7397\n",
            "Epoch 610/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6949 - accuracy: 0.7476\n",
            "Epoch 611/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7177 - accuracy: 0.7417\n",
            "Epoch 612/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7141 - accuracy: 0.7442\n",
            "Epoch 613/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7173 - accuracy: 0.7496\n",
            "Epoch 614/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7063 - accuracy: 0.7526\n",
            "Epoch 615/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7180 - accuracy: 0.7476\n",
            "Epoch 616/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7584 - accuracy: 0.7392\n",
            "Epoch 617/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7244 - accuracy: 0.7442\n",
            "Epoch 618/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7016 - accuracy: 0.7486\n",
            "Epoch 619/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7321 - accuracy: 0.7368\n",
            "Epoch 620/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7135 - accuracy: 0.7457\n",
            "Epoch 621/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7538 - accuracy: 0.7333\n",
            "Epoch 622/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7399 - accuracy: 0.7353\n",
            "Epoch 623/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7094 - accuracy: 0.7452\n",
            "Epoch 624/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7143 - accuracy: 0.7457\n",
            "Epoch 625/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7227 - accuracy: 0.7442\n",
            "Epoch 626/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7203 - accuracy: 0.7501\n",
            "Epoch 627/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7068 - accuracy: 0.7516\n",
            "Epoch 628/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6770 - accuracy: 0.7600\n",
            "Epoch 629/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7267 - accuracy: 0.7432\n",
            "Epoch 630/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7552 - accuracy: 0.7328\n",
            "Epoch 631/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7583 - accuracy: 0.7293\n",
            "Epoch 632/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7125 - accuracy: 0.7462\n",
            "Epoch 633/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7419 - accuracy: 0.7358\n",
            "Epoch 634/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7303 - accuracy: 0.7476\n",
            "Epoch 635/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6910 - accuracy: 0.7506\n",
            "Epoch 636/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7243 - accuracy: 0.7472\n",
            "Epoch 637/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7285 - accuracy: 0.7402\n",
            "Epoch 638/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7081 - accuracy: 0.7462\n",
            "Epoch 639/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7075 - accuracy: 0.7496\n",
            "Epoch 640/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7507 - accuracy: 0.7358\n",
            "Epoch 641/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7260 - accuracy: 0.7481\n",
            "Epoch 642/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7351 - accuracy: 0.7407\n",
            "Epoch 643/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7090 - accuracy: 0.7442\n",
            "Epoch 644/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7519 - accuracy: 0.7368\n",
            "Epoch 645/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7631 - accuracy: 0.7382\n",
            "Epoch 646/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6749 - accuracy: 0.7531\n",
            "Epoch 647/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7087 - accuracy: 0.7585\n",
            "Epoch 648/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7231 - accuracy: 0.7442\n",
            "Epoch 649/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7026 - accuracy: 0.7660\n",
            "Epoch 650/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7143 - accuracy: 0.7551\n",
            "Epoch 651/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7535 - accuracy: 0.7422\n",
            "Epoch 652/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7237 - accuracy: 0.7437\n",
            "Epoch 653/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7096 - accuracy: 0.7486\n",
            "Epoch 654/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6994 - accuracy: 0.7531\n",
            "Epoch 655/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7337 - accuracy: 0.7486\n",
            "Epoch 656/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7311 - accuracy: 0.7462\n",
            "Epoch 657/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6989 - accuracy: 0.7595\n",
            "Epoch 658/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7381 - accuracy: 0.7412\n",
            "Epoch 659/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7260 - accuracy: 0.7467\n",
            "Epoch 660/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7141 - accuracy: 0.7501\n",
            "Epoch 661/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7142 - accuracy: 0.7452\n",
            "Epoch 662/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7406 - accuracy: 0.7452\n",
            "Epoch 663/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7366 - accuracy: 0.7284\n",
            "Epoch 664/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7617 - accuracy: 0.7343\n",
            "Epoch 665/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7666 - accuracy: 0.7363\n",
            "Epoch 666/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.8314 - accuracy: 0.7165\n",
            "Epoch 667/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7702 - accuracy: 0.7373\n",
            "Epoch 668/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7557 - accuracy: 0.7358\n",
            "Epoch 669/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7128 - accuracy: 0.7486\n",
            "Epoch 670/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7393 - accuracy: 0.7387\n",
            "Epoch 671/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6908 - accuracy: 0.7585\n",
            "Epoch 672/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7485 - accuracy: 0.7417\n",
            "Epoch 673/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7496 - accuracy: 0.7392\n",
            "Epoch 674/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6941 - accuracy: 0.7516\n",
            "Epoch 675/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7217 - accuracy: 0.7422\n",
            "Epoch 676/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7790 - accuracy: 0.7224\n",
            "Epoch 677/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7165 - accuracy: 0.7486\n",
            "Epoch 678/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6986 - accuracy: 0.7526\n",
            "Epoch 679/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7003 - accuracy: 0.7546\n",
            "Epoch 680/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7223 - accuracy: 0.7457\n",
            "Epoch 681/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7066 - accuracy: 0.7536\n",
            "Epoch 682/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7404 - accuracy: 0.7422\n",
            "Epoch 683/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7274 - accuracy: 0.7437\n",
            "Epoch 684/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7287 - accuracy: 0.7417\n",
            "Epoch 685/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6993 - accuracy: 0.7526\n",
            "Epoch 686/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7589 - accuracy: 0.7333\n",
            "Epoch 687/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7622 - accuracy: 0.7373\n",
            "Epoch 688/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.8266 - accuracy: 0.7150\n",
            "Epoch 689/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6987 - accuracy: 0.7561\n",
            "Epoch 690/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7137 - accuracy: 0.7432\n",
            "Epoch 691/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7773 - accuracy: 0.7279\n",
            "Epoch 692/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7419 - accuracy: 0.7452\n",
            "Epoch 693/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7088 - accuracy: 0.7630\n",
            "Epoch 694/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7589 - accuracy: 0.7397\n",
            "Epoch 695/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7315 - accuracy: 0.7417\n",
            "Epoch 696/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7361 - accuracy: 0.7373\n",
            "Epoch 697/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7306 - accuracy: 0.7348\n",
            "Epoch 698/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7299 - accuracy: 0.7417\n",
            "Epoch 699/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7143 - accuracy: 0.7447\n",
            "Epoch 700/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6909 - accuracy: 0.7556\n",
            "Epoch 701/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6850 - accuracy: 0.7620\n",
            "Epoch 702/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6566 - accuracy: 0.7665\n",
            "Epoch 703/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6839 - accuracy: 0.7630\n",
            "Epoch 704/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7038 - accuracy: 0.7561\n",
            "Epoch 705/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6942 - accuracy: 0.7610\n",
            "Epoch 706/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7230 - accuracy: 0.7417\n",
            "Epoch 707/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7369 - accuracy: 0.7392\n",
            "Epoch 708/1000\n",
            "32/32 [==============================] - 4s 131ms/step - loss: 0.7330 - accuracy: 0.7397\n",
            "Epoch 709/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7221 - accuracy: 0.7476\n",
            "Epoch 710/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7346 - accuracy: 0.7338\n",
            "Epoch 711/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6898 - accuracy: 0.7615\n",
            "Epoch 712/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7237 - accuracy: 0.7412\n",
            "Epoch 713/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6983 - accuracy: 0.7531\n",
            "Epoch 714/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7530 - accuracy: 0.7392\n",
            "Epoch 715/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7007 - accuracy: 0.7496\n",
            "Epoch 716/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7422 - accuracy: 0.7378\n",
            "Epoch 717/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7177 - accuracy: 0.7476\n",
            "Epoch 718/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7248 - accuracy: 0.7392\n",
            "Epoch 719/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7221 - accuracy: 0.7472\n",
            "Epoch 720/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7318 - accuracy: 0.7333\n",
            "Epoch 721/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7483 - accuracy: 0.7254\n",
            "Epoch 722/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7558 - accuracy: 0.7353\n",
            "Epoch 723/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6636 - accuracy: 0.7620\n",
            "Epoch 724/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7087 - accuracy: 0.7467\n",
            "Epoch 725/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7209 - accuracy: 0.7506\n",
            "Epoch 726/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7255 - accuracy: 0.7452\n",
            "Epoch 727/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6753 - accuracy: 0.7595\n",
            "Epoch 728/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6799 - accuracy: 0.7640\n",
            "Epoch 729/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7167 - accuracy: 0.7476\n",
            "Epoch 730/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7129 - accuracy: 0.7575\n",
            "Epoch 731/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7449 - accuracy: 0.7412\n",
            "Epoch 732/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7307 - accuracy: 0.7486\n",
            "Epoch 733/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7243 - accuracy: 0.7402\n",
            "Epoch 734/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7171 - accuracy: 0.7546\n",
            "Epoch 735/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7375 - accuracy: 0.7368\n",
            "Epoch 736/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7288 - accuracy: 0.7308\n",
            "Epoch 737/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7641 - accuracy: 0.7447\n",
            "Epoch 738/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7695 - accuracy: 0.7318\n",
            "Epoch 739/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7028 - accuracy: 0.7501\n",
            "Epoch 740/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7413 - accuracy: 0.7397\n",
            "Epoch 741/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7179 - accuracy: 0.7501\n",
            "Epoch 742/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7327 - accuracy: 0.7452\n",
            "Epoch 743/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7204 - accuracy: 0.7457\n",
            "Epoch 744/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7780 - accuracy: 0.7313\n",
            "Epoch 745/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6896 - accuracy: 0.7580\n",
            "Epoch 746/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6986 - accuracy: 0.7561\n",
            "Epoch 747/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7344 - accuracy: 0.7462\n",
            "Epoch 748/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7017 - accuracy: 0.7561\n",
            "Epoch 749/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7457 - accuracy: 0.7358\n",
            "Epoch 750/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7652 - accuracy: 0.7308\n",
            "Epoch 751/1000\n",
            "32/32 [==============================] - 4s 131ms/step - loss: 0.7119 - accuracy: 0.7541\n",
            "Epoch 752/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6921 - accuracy: 0.7625\n",
            "Epoch 753/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7128 - accuracy: 0.7521\n",
            "Epoch 754/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7176 - accuracy: 0.7447\n",
            "Epoch 755/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7072 - accuracy: 0.7491\n",
            "Epoch 756/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7103 - accuracy: 0.7556\n",
            "Epoch 757/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7382 - accuracy: 0.7412\n",
            "Epoch 758/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7675 - accuracy: 0.7338\n",
            "Epoch 759/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7196 - accuracy: 0.7462\n",
            "Epoch 760/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7537 - accuracy: 0.7373\n",
            "Epoch 761/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7144 - accuracy: 0.7496\n",
            "Epoch 762/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7166 - accuracy: 0.7536\n",
            "Epoch 763/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7234 - accuracy: 0.7541\n",
            "Epoch 764/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7175 - accuracy: 0.7442\n",
            "Epoch 765/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7573 - accuracy: 0.7293\n",
            "Epoch 766/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7260 - accuracy: 0.7397\n",
            "Epoch 767/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7307 - accuracy: 0.7363\n",
            "Epoch 768/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6983 - accuracy: 0.7506\n",
            "Epoch 769/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6946 - accuracy: 0.7496\n",
            "Epoch 770/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7219 - accuracy: 0.7382\n",
            "Epoch 771/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7315 - accuracy: 0.7432\n",
            "Epoch 772/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7296 - accuracy: 0.7447\n",
            "Epoch 773/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7239 - accuracy: 0.7481\n",
            "Epoch 774/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7496 - accuracy: 0.7279\n",
            "Epoch 775/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7252 - accuracy: 0.7447\n",
            "Epoch 776/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7329 - accuracy: 0.7333\n",
            "Epoch 777/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7357 - accuracy: 0.7447\n",
            "Epoch 778/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7515 - accuracy: 0.7378\n",
            "Epoch 779/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7698 - accuracy: 0.7279\n",
            "Epoch 780/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7377 - accuracy: 0.7353\n",
            "Epoch 781/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7152 - accuracy: 0.7447\n",
            "Epoch 782/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7104 - accuracy: 0.7496\n",
            "Epoch 783/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7196 - accuracy: 0.7447\n",
            "Epoch 784/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6831 - accuracy: 0.7526\n",
            "Epoch 785/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6980 - accuracy: 0.7541\n",
            "Epoch 786/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6658 - accuracy: 0.7640\n",
            "Epoch 787/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6968 - accuracy: 0.7536\n",
            "Epoch 788/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6927 - accuracy: 0.7506\n",
            "Epoch 789/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7194 - accuracy: 0.7457\n",
            "Epoch 790/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7151 - accuracy: 0.7407\n",
            "Epoch 791/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7257 - accuracy: 0.7387\n",
            "Epoch 792/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7457 - accuracy: 0.7333\n",
            "Epoch 793/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7519 - accuracy: 0.7333\n",
            "Epoch 794/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7074 - accuracy: 0.7556\n",
            "Epoch 795/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7390 - accuracy: 0.7358\n",
            "Epoch 796/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7421 - accuracy: 0.7333\n",
            "Epoch 797/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7121 - accuracy: 0.7501\n",
            "Epoch 798/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7048 - accuracy: 0.7472\n",
            "Epoch 799/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7261 - accuracy: 0.7486\n",
            "Epoch 800/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7480 - accuracy: 0.7368\n",
            "Epoch 801/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7508 - accuracy: 0.7274\n",
            "Epoch 802/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6920 - accuracy: 0.7486\n",
            "Epoch 803/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7204 - accuracy: 0.7422\n",
            "Epoch 804/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6898 - accuracy: 0.7531\n",
            "Epoch 805/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6856 - accuracy: 0.7595\n",
            "Epoch 806/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7028 - accuracy: 0.7457\n",
            "Epoch 807/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7468 - accuracy: 0.7373\n",
            "Epoch 808/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7453 - accuracy: 0.7368\n",
            "Epoch 809/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7017 - accuracy: 0.7541\n",
            "Epoch 810/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6977 - accuracy: 0.7531\n",
            "Epoch 811/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7358 - accuracy: 0.7382\n",
            "Epoch 812/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7004 - accuracy: 0.7496\n",
            "Epoch 813/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7332 - accuracy: 0.7407\n",
            "Epoch 814/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6904 - accuracy: 0.7546\n",
            "Epoch 815/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7293 - accuracy: 0.7387\n",
            "Epoch 816/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7487 - accuracy: 0.7328\n",
            "Epoch 817/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7457 - accuracy: 0.7462\n",
            "Epoch 818/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7168 - accuracy: 0.7437\n",
            "Epoch 819/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7205 - accuracy: 0.7397\n",
            "Epoch 820/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7158 - accuracy: 0.7427\n",
            "Epoch 821/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7292 - accuracy: 0.7397\n",
            "Epoch 822/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7594 - accuracy: 0.7323\n",
            "Epoch 823/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6815 - accuracy: 0.7546\n",
            "Epoch 824/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7274 - accuracy: 0.7373\n",
            "Epoch 825/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6996 - accuracy: 0.7516\n",
            "Epoch 826/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6897 - accuracy: 0.7551\n",
            "Epoch 827/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6759 - accuracy: 0.7645\n",
            "Epoch 828/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7361 - accuracy: 0.7387\n",
            "Epoch 829/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7561 - accuracy: 0.7387\n",
            "Epoch 830/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7320 - accuracy: 0.7481\n",
            "Epoch 831/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7505 - accuracy: 0.7363\n",
            "Epoch 832/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7284 - accuracy: 0.7516\n",
            "Epoch 833/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7227 - accuracy: 0.7467\n",
            "Epoch 834/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7382 - accuracy: 0.7338\n",
            "Epoch 835/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7267 - accuracy: 0.7437\n",
            "Epoch 836/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7320 - accuracy: 0.7412\n",
            "Epoch 837/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7410 - accuracy: 0.7313\n",
            "Epoch 838/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7125 - accuracy: 0.7496\n",
            "Epoch 839/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7243 - accuracy: 0.7437\n",
            "Epoch 840/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6861 - accuracy: 0.7561\n",
            "Epoch 841/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7320 - accuracy: 0.7333\n",
            "Epoch 842/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7130 - accuracy: 0.7472\n",
            "Epoch 843/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7019 - accuracy: 0.7452\n",
            "Epoch 844/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7009 - accuracy: 0.7462\n",
            "Epoch 845/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7321 - accuracy: 0.7387\n",
            "Epoch 846/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7046 - accuracy: 0.7437\n",
            "Epoch 847/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7388 - accuracy: 0.7412\n",
            "Epoch 848/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7240 - accuracy: 0.7378\n",
            "Epoch 849/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7293 - accuracy: 0.7417\n",
            "Epoch 850/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6919 - accuracy: 0.7546\n",
            "Epoch 851/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7225 - accuracy: 0.7358\n",
            "Epoch 852/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7027 - accuracy: 0.7472\n",
            "Epoch 853/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7015 - accuracy: 0.7521\n",
            "Epoch 854/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7174 - accuracy: 0.7447\n",
            "Epoch 855/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7211 - accuracy: 0.7387\n",
            "Epoch 856/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7194 - accuracy: 0.7402\n",
            "Epoch 857/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6973 - accuracy: 0.7541\n",
            "Epoch 858/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7475 - accuracy: 0.7358\n",
            "Epoch 859/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6925 - accuracy: 0.7506\n",
            "Epoch 860/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7063 - accuracy: 0.7526\n",
            "Epoch 861/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7030 - accuracy: 0.7516\n",
            "Epoch 862/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7010 - accuracy: 0.7481\n",
            "Epoch 863/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7251 - accuracy: 0.7328\n",
            "Epoch 864/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7947 - accuracy: 0.7214\n",
            "Epoch 865/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7384 - accuracy: 0.7353\n",
            "Epoch 866/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7398 - accuracy: 0.7333\n",
            "Epoch 867/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7125 - accuracy: 0.7551\n",
            "Epoch 868/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7135 - accuracy: 0.7496\n",
            "Epoch 869/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7219 - accuracy: 0.7412\n",
            "Epoch 870/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7072 - accuracy: 0.7472\n",
            "Epoch 871/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6976 - accuracy: 0.7541\n",
            "Epoch 872/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7348 - accuracy: 0.7412\n",
            "Epoch 873/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7188 - accuracy: 0.7427\n",
            "Epoch 874/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7419 - accuracy: 0.7437\n",
            "Epoch 875/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7595 - accuracy: 0.7402\n",
            "Epoch 876/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7258 - accuracy: 0.7476\n",
            "Epoch 877/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7145 - accuracy: 0.7516\n",
            "Epoch 878/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7223 - accuracy: 0.7442\n",
            "Epoch 879/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7466 - accuracy: 0.7348\n",
            "Epoch 880/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6858 - accuracy: 0.7566\n",
            "Epoch 881/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7269 - accuracy: 0.7437\n",
            "Epoch 882/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7088 - accuracy: 0.7521\n",
            "Epoch 883/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7198 - accuracy: 0.7511\n",
            "Epoch 884/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7609 - accuracy: 0.7298\n",
            "Epoch 885/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7091 - accuracy: 0.7486\n",
            "Epoch 886/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7458 - accuracy: 0.7417\n",
            "Epoch 887/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7678 - accuracy: 0.7397\n",
            "Epoch 888/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7470 - accuracy: 0.7318\n",
            "Epoch 889/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7213 - accuracy: 0.7457\n",
            "Epoch 890/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7147 - accuracy: 0.7511\n",
            "Epoch 891/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6895 - accuracy: 0.7580\n",
            "Epoch 892/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6968 - accuracy: 0.7526\n",
            "Epoch 893/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7416 - accuracy: 0.7387\n",
            "Epoch 894/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.7583 - accuracy: 0.7293\n",
            "Epoch 895/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6954 - accuracy: 0.7541\n",
            "Epoch 896/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7225 - accuracy: 0.7412\n",
            "Epoch 897/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7142 - accuracy: 0.7486\n",
            "Epoch 898/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7069 - accuracy: 0.7397\n",
            "Epoch 899/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7006 - accuracy: 0.7432\n",
            "Epoch 900/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7161 - accuracy: 0.7521\n",
            "Epoch 901/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7584 - accuracy: 0.7338\n",
            "Epoch 902/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7135 - accuracy: 0.7472\n",
            "Epoch 903/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7231 - accuracy: 0.7373\n",
            "Epoch 904/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7264 - accuracy: 0.7353\n",
            "Epoch 905/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6947 - accuracy: 0.7556\n",
            "Epoch 906/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7136 - accuracy: 0.7437\n",
            "Epoch 907/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7129 - accuracy: 0.7467\n",
            "Epoch 908/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7100 - accuracy: 0.7467\n",
            "Epoch 909/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6998 - accuracy: 0.7521\n",
            "Epoch 910/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7292 - accuracy: 0.7373\n",
            "Epoch 911/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7236 - accuracy: 0.7392\n",
            "Epoch 912/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7451 - accuracy: 0.7298\n",
            "Epoch 913/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6977 - accuracy: 0.7546\n",
            "Epoch 914/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6905 - accuracy: 0.7561\n",
            "Epoch 915/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7142 - accuracy: 0.7476\n",
            "Epoch 916/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7256 - accuracy: 0.7491\n",
            "Epoch 917/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7701 - accuracy: 0.7194\n",
            "Epoch 918/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7209 - accuracy: 0.7452\n",
            "Epoch 919/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7277 - accuracy: 0.7353\n",
            "Epoch 920/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6780 - accuracy: 0.7571\n",
            "Epoch 921/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7262 - accuracy: 0.7407\n",
            "Epoch 922/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7065 - accuracy: 0.7437\n",
            "Epoch 923/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6946 - accuracy: 0.7541\n",
            "Epoch 924/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6776 - accuracy: 0.7561\n",
            "Epoch 925/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7112 - accuracy: 0.7472\n",
            "Epoch 926/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6627 - accuracy: 0.7660\n",
            "Epoch 927/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6911 - accuracy: 0.7521\n",
            "Epoch 928/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6979 - accuracy: 0.7561\n",
            "Epoch 929/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6987 - accuracy: 0.7506\n",
            "Epoch 930/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7290 - accuracy: 0.7348\n",
            "Epoch 931/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7272 - accuracy: 0.7373\n",
            "Epoch 932/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7204 - accuracy: 0.7392\n",
            "Epoch 933/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7219 - accuracy: 0.7467\n",
            "Epoch 934/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7247 - accuracy: 0.7447\n",
            "Epoch 935/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7103 - accuracy: 0.7526\n",
            "Epoch 936/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7047 - accuracy: 0.7531\n",
            "Epoch 937/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7560 - accuracy: 0.7343\n",
            "Epoch 938/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7510 - accuracy: 0.7392\n",
            "Epoch 939/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7154 - accuracy: 0.7501\n",
            "Epoch 940/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7388 - accuracy: 0.7496\n",
            "Epoch 941/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7463 - accuracy: 0.7397\n",
            "Epoch 942/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7356 - accuracy: 0.7442\n",
            "Epoch 943/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7528 - accuracy: 0.7368\n",
            "Epoch 944/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7342 - accuracy: 0.7387\n",
            "Epoch 945/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7230 - accuracy: 0.7392\n",
            "Epoch 946/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7349 - accuracy: 0.7392\n",
            "Epoch 947/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7473 - accuracy: 0.7368\n",
            "Epoch 948/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7070 - accuracy: 0.7476\n",
            "Epoch 949/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.6890 - accuracy: 0.7536\n",
            "Epoch 950/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7248 - accuracy: 0.7387\n",
            "Epoch 951/1000\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.6626 - accuracy: 0.7645\n",
            "Epoch 952/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7058 - accuracy: 0.7462\n",
            "Epoch 953/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7274 - accuracy: 0.7373\n",
            "Epoch 954/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6936 - accuracy: 0.7566\n",
            "Epoch 955/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7104 - accuracy: 0.7442\n",
            "Epoch 956/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7067 - accuracy: 0.7501\n",
            "Epoch 957/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7144 - accuracy: 0.7462\n",
            "Epoch 958/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6915 - accuracy: 0.7580\n",
            "Epoch 959/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.7394 - accuracy: 0.7382\n",
            "Epoch 960/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7457 - accuracy: 0.7382\n",
            "Epoch 961/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7199 - accuracy: 0.7442\n",
            "Epoch 962/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7414 - accuracy: 0.7422\n",
            "Epoch 963/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7126 - accuracy: 0.7551\n",
            "Epoch 964/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7192 - accuracy: 0.7476\n",
            "Epoch 965/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7084 - accuracy: 0.7481\n",
            "Epoch 966/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7077 - accuracy: 0.7472\n",
            "Epoch 967/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6936 - accuracy: 0.7511\n",
            "Epoch 968/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6914 - accuracy: 0.7511\n",
            "Epoch 969/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7015 - accuracy: 0.7467\n",
            "Epoch 970/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6921 - accuracy: 0.7556\n",
            "Epoch 971/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6706 - accuracy: 0.7620\n",
            "Epoch 972/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7160 - accuracy: 0.7432\n",
            "Epoch 973/1000\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.7074 - accuracy: 0.7516\n",
            "Epoch 974/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7135 - accuracy: 0.7422\n",
            "Epoch 975/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.6664 - accuracy: 0.7630\n",
            "Epoch 976/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7001 - accuracy: 0.7546\n",
            "Epoch 977/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7267 - accuracy: 0.7432\n",
            "Epoch 978/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6992 - accuracy: 0.7501\n",
            "Epoch 979/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7002 - accuracy: 0.7501\n",
            "Epoch 980/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6680 - accuracy: 0.7625\n",
            "Epoch 981/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7093 - accuracy: 0.7521\n",
            "Epoch 982/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6616 - accuracy: 0.7610\n",
            "Epoch 983/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6982 - accuracy: 0.7531\n",
            "Epoch 984/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7065 - accuracy: 0.7442\n",
            "Epoch 985/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7130 - accuracy: 0.7442\n",
            "Epoch 986/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.7224 - accuracy: 0.7442\n",
            "Epoch 987/1000\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.7134 - accuracy: 0.7506\n",
            "Epoch 988/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.7055 - accuracy: 0.7541\n",
            "Epoch 989/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6335 - accuracy: 0.7843\n",
            "Epoch 990/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6091 - accuracy: 0.7808\n",
            "Epoch 991/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.6165 - accuracy: 0.7843\n",
            "Epoch 992/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.6219 - accuracy: 0.7739\n",
            "Epoch 993/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.5392 - accuracy: 0.8090\n",
            "Epoch 994/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.5743 - accuracy: 0.7882\n",
            "Epoch 995/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.5407 - accuracy: 0.8031\n",
            "Epoch 996/1000\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.5650 - accuracy: 0.7981\n",
            "Epoch 997/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.5635 - accuracy: 0.7952\n",
            "Epoch 998/1000\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.5402 - accuracy: 0.8031\n",
            "Epoch 999/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.5151 - accuracy: 0.8115\n",
            "Epoch 1000/1000\n",
            "32/32 [==============================] - 4s 128ms/step - loss: 0.5386 - accuracy: 0.8060\n",
            "Returned: <keras.callbacks.History object at 0x7fd9203af7d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "#plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MGi_V_Akbo56",
        "outputId": "0fdf5f5b-860d-4e85-952f-815d5bb9a571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "#plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uJCsAUTRbqIA",
        "outputId": "b0f78f6c-d090-4794-be6c-44b9d1f24fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efUXZx9_dktN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retorna(y):\n",
        "  resp = []\n",
        "  for yi in y:\n",
        "    vmax =max(yi)\n",
        "    for idx, x in enumerate(yi):\n",
        "      if(x == vmax):\n",
        "        resp.append(idx)\n",
        "  return resp"
      ],
      "metadata": {
        "id": "xdlcp6zcZ6hT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n"
      ],
      "metadata": {
        "id": "mXNt2lL7aH0g",
        "outputId": "9a9ea8da-644f-4065-82a7-a1f7ae6fc9b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 - 1s - loss: 6.6061 - accuracy: 0.6265 - 1s/epoch - 63ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.__version__"
      ],
      "metadata": {
        "id": "T36u6fVlkYMh",
        "outputId": "ee0ece1f-355e-4d2f-84ec-ff72070e9908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.3.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict=model.predict(X_test) "
      ],
      "metadata": {
        "id": "y7yYVDv3f6nQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_calc = retorna(predict)\n",
        "y_test = retorna(np.array(y_test))"
      ],
      "metadata": {
        "id": "XpSn6Htz5O4l"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_calc)"
      ],
      "metadata": {
        "id": "4HToHynCM43p",
        "outputId": "5e7b72f6-d9f5-4094-a72b-4075990549ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[55,  3,  7,  7,  9,  0],\n",
              "       [ 1, 60, 29,  1,  9,  0],\n",
              "       [ 6,  9, 53,  4, 10,  0],\n",
              "       [ 4,  1, 20, 92,  2,  0],\n",
              "       [ 8, 15, 15,  2, 57,  0],\n",
              "       [ 7,  1,  3,  1, 15,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print('\\n\\n', classification_report(y_test, y_calc, target_names=tipos))"
      ],
      "metadata": {
        "id": "ERrFAB10Om7P",
        "outputId": "bd7c46f6-5da2-4e94-f112-7012686da5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.68      0.68      0.68        81\n",
            "       glass       0.67      0.60      0.63       100\n",
            "       metal       0.42      0.65      0.51        82\n",
            "       paper       0.86      0.77      0.81       119\n",
            "     plastic       0.56      0.59      0.57        97\n",
            "       trash       0.00      0.00      0.00        27\n",
            "\n",
            "    accuracy                           0.63       506\n",
            "   macro avg       0.53      0.55      0.53       506\n",
            "weighted avg       0.62      0.63      0.62       506\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print('\\n\\n', classification_report(y_test, y_test, target_names=tipos))"
      ],
      "metadata": {
        "id": "tQ4iLQcdliMX",
        "outputId": "aeca6095-57fa-4a27-84f8-40719e6c6336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       1.00      1.00      1.00        81\n",
            "       glass       1.00      1.00      1.00       100\n",
            "       metal       1.00      1.00      1.00        82\n",
            "       paper       1.00      1.00      1.00       119\n",
            "     plastic       1.00      1.00      1.00        97\n",
            "       trash       1.00      1.00      1.00        27\n",
            "\n",
            "    accuracy                           1.00       506\n",
            "   macro avg       1.00      1.00      1.00       506\n",
            "weighted avg       1.00      1.00      1.00       506\n",
            "\n"
          ]
        }
      ]
    }
  ]
}