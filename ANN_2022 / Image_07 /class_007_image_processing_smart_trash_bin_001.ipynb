{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtNIEFI6OFePTmyFSEWAQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/ANN/blob/master/ANN_2022%20/%20Image_07%20/class_007_image_processing_smart_trash_bin_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import zipfile\n",
        "from matplotlib import pyplot as plt\n",
        "import skimage.feature\n",
        "from string import digits\n",
        "import seaborn as sns\n",
        "import skimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "7wNxYQBaKVJQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "JNNoeVHgb9WL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea3bxyjq-kcq",
        "outputId": "91e3d70b-5ded-4cef-b8b4-3794c1682b8a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L4mdCDBgybKqr5Wo-kqT8HXcBJ9HXqSX\n",
            "To: /content/trash_nov_22_2018.zip\n",
            "100% 42.8M/42.8M [00:00<00:00, 193MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FILE='trash_nov_22_2018.zip'"
      ],
      "metadata": {
        "id": "oyLilZ2l-loH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archive = zipfile.ZipFile('trash_nov_22_2018.zip', 'r')\n",
        "archive.extractall()"
      ],
      "metadata": {
        "id": "XwXGEOlF_K1c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_name=[]\n",
        "with zipfile.ZipFile(FILE, \"r\") as f:\n",
        "    for name in f.namelist():\n",
        "        img_name.append(name)"
      ],
      "metadata": {
        "id": "cs5xKcmpAgOA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Img_Size = 224\n",
        "ref = 'jpg'\n",
        "notref = 'met'"
      ],
      "metadata": {
        "id": "PVPFW06o_kw8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= []  \n",
        "Y =[]\n",
        "n = len(img_name)\n",
        "i = 0\n",
        "for i in range(n):\n",
        "  name = img_name[i]\n",
        "  if(ref in name):\n",
        "    Y.append(name)\n",
        "    img = cv2.imread(name)\n",
        "    resized = cv2.resize(img, (Img_Size,Img_Size))\n",
        "    X.append(resized)\n",
        "m = len(Y)\n",
        "print(n,m)"
      ],
      "metadata": {
        "id": "lAOB3uC3JG2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83adfed4-6ae0-4168-a035-604e349e6239"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2527 2527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "tipos = []\n",
        "selected = 'find'\n",
        "for x in img_name:\n",
        "  result =''.join([i for i in x[:-4] if not i.isdigit()])\n",
        "  if(result != selected):\n",
        "    selected = result\n",
        "    tipos.append(selected)\n"
      ],
      "metadata": {
        "id": "5Kh0R80ndBQ0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label =[]\n",
        "for name in img_name:\n",
        "  for idx, x in enumerate(tipos):\n",
        "    if(x in name):\n",
        "      label.append(idx)"
      ],
      "metadata": {
        "id": "MejkwNSX1kOi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(label,columns=['target'])"
      ],
      "metadata": {
        "id": "GyKMP7gCScy4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.get_dummies(df['target'])"
      ],
      "metadata": {
        "id": "YGlSEZ5O3pkf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6): \n",
        "  n= df[(df[\"target\"] == i)].shape[0]\n",
        "  print(tipos[i],n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CDIVizOZXv",
        "outputId": "21286e80-9b96-4a84-9f7c-a2e5e8545a2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cardboard 403\n",
            "glass 501\n",
            "metal 410\n",
            "paper 594\n",
            "plastic 482\n",
            "trash 137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label"
      ],
      "metadata": {
        "id": "nZ_iIcFRNue7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "data = np.empty((n, 224, 224, 3))"
      ],
      "metadata": {
        "id": "Y0IiAVMPNZF9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pythontutorials.eu/deep-learning/transfer-learning/"
      ],
      "metadata": {
        "id": "g5xlAJuoOle1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_SIZE = len(img_name)\n",
        "Ind = range(DATASET_SIZE)\n",
        "Ind_train, Ind_test= train_test_split(Ind,test_size=0.20,stratify=label, shuffle=True, random_state=3)\n",
        "X = np.array(X)\n",
        "X_train=X[Ind_train]\n",
        "X_test = X[Ind_test]\n",
        "y_train=y.iloc[Ind_train,:]\n",
        "y_test = y.iloc[Ind_test,:]"
      ],
      "metadata": {
        "id": "xJyag03ml4jj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from skimage.transform import resize\n",
        "i = 0\n",
        "for im in X:\n",
        "    im = preprocess_input(im)\n",
        "    im = resize(im, output_shape=(224, 224))\n",
        "    data[i] = im\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "VVRS0r0UNzw8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N7fPiisPnkF",
        "outputId": "cda020b5-4e72-45e2-da4b-4efa374b321d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2527"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n =len(img_name)\n",
        "m = len(tipos)\n",
        "\n",
        "'''\n",
        "labels_tf = np.empty(n, dtype=int)\n",
        "for idx, yi in enumerate(label):\n",
        "  labels_tf[idx] = yi\n",
        "'''\n",
        "idx = 0\n",
        "labels_tf = np.empty([n,m], dtype=int)\n",
        "for yi in y.values:\n",
        "  labels_tf[idx] = yi\n",
        "  idx = idx + 1\n",
        "\n"
      ],
      "metadata": {
        "id": "rcgv-joQO61M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "model = MobileNetV2(weights='imagenet')"
      ],
      "metadata": {
        "id": "EwENgCGxQVS8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet_v2 import decode_predictions\n",
        "\n",
        "predictions = model.predict(data)\n",
        "k = 0\n",
        "for decoded_prediction in decode_predictions(predictions, top=1):\n",
        "  \n",
        "  for name, desc, score in decoded_prediction:\n",
        "      if(k % 200 ==0):\n",
        "        print('- {} ({:.2f}%%) {}'.format(desc, 100 * score,img_name[k]))\n",
        "  k = k +1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooc62gF9QWUE",
        "outputId": "31f2ad6e-6df4-4002-943d-ada5a49d4208"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 6s 38ms/step\n",
            "- envelope (27.77%%) cardboard1.jpg\n",
            "- mailbag (27.79%%) cardboard201.jpg\n",
            "- velvet (10.09%%) cardboard401.jpg\n",
            "- ballpoint (13.35%%) glass198.jpg\n",
            "- spotlight (96.14%%) glass398.jpg\n",
            "- water_bottle (24.05%%) metal97.jpg\n",
            "- ashcan (71.91%%) metal297.jpg\n",
            "- syringe (20.62%%) paper87.jpg\n",
            "- shopping_cart (10.26%%) paper287.jpg\n",
            "- hand-held_computer (23.41%%) paper487.jpg\n",
            "- water_bottle (18.48%%) plastic93.jpg\n",
            "- water_bottle (60.90%%) plastic293.jpg\n",
            "- plastic_bag (69.38%%) trash11.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "D = len(tipos)\n",
        "model_output = Dense(D, activation='softmax')"
      ],
      "metadata": {
        "id": "j3I5nZ8dRYKd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = model_output(model.layers[-2].output)"
      ],
      "metadata": {
        "id": "bz08xnbiTn7e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Model\n",
        "\n",
        "model_input = model.input\n",
        "model_model = Model(inputs=model_input, outputs=model_output)"
      ],
      "metadata": {
        "id": "IqaB8H5ETs0W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_model.layers[:-1]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "n3oiO5lkTueV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "mZ2SZgLgTzq9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_model.fit(x=data, y=labels_tf, epochs=20, verbose=2) \n",
        "model_model.fit(x=X_train, y=y_train, epochs=50, verbose=2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9SymbkpT6tl",
        "outputId": "191f4513-9714-469a-d096-a54693143af2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "64/64 - 5s - loss: 1.3530 - accuracy: 0.4800 - 5s/epoch - 82ms/step\n",
            "Epoch 2/50\n",
            "64/64 - 2s - loss: 1.0352 - accuracy: 0.6170 - 2s/epoch - 36ms/step\n",
            "Epoch 3/50\n",
            "64/64 - 2s - loss: 0.9292 - accuracy: 0.6650 - 2s/epoch - 36ms/step\n",
            "Epoch 4/50\n",
            "64/64 - 2s - loss: 0.8648 - accuracy: 0.6917 - 2s/epoch - 36ms/step\n",
            "Epoch 5/50\n",
            "64/64 - 2s - loss: 0.8301 - accuracy: 0.7115 - 2s/epoch - 35ms/step\n",
            "Epoch 6/50\n",
            "64/64 - 2s - loss: 0.7781 - accuracy: 0.7279 - 2s/epoch - 35ms/step\n",
            "Epoch 7/50\n",
            "64/64 - 2s - loss: 0.7428 - accuracy: 0.7462 - 2s/epoch - 36ms/step\n",
            "Epoch 8/50\n",
            "64/64 - 2s - loss: 0.7106 - accuracy: 0.7615 - 2s/epoch - 36ms/step\n",
            "Epoch 9/50\n",
            "64/64 - 2s - loss: 0.6837 - accuracy: 0.7660 - 2s/epoch - 36ms/step\n",
            "Epoch 10/50\n",
            "64/64 - 2s - loss: 0.6657 - accuracy: 0.7783 - 2s/epoch - 35ms/step\n",
            "Epoch 11/50\n",
            "64/64 - 2s - loss: 0.6416 - accuracy: 0.7912 - 2s/epoch - 36ms/step\n",
            "Epoch 12/50\n",
            "64/64 - 2s - loss: 0.6260 - accuracy: 0.7872 - 2s/epoch - 36ms/step\n",
            "Epoch 13/50\n",
            "64/64 - 2s - loss: 0.6103 - accuracy: 0.7961 - 2s/epoch - 36ms/step\n",
            "Epoch 14/50\n",
            "64/64 - 2s - loss: 0.5895 - accuracy: 0.8016 - 2s/epoch - 37ms/step\n",
            "Epoch 15/50\n",
            "64/64 - 2s - loss: 0.5747 - accuracy: 0.8080 - 2s/epoch - 37ms/step\n",
            "Epoch 16/50\n",
            "64/64 - 2s - loss: 0.5619 - accuracy: 0.8090 - 2s/epoch - 36ms/step\n",
            "Epoch 17/50\n",
            "64/64 - 2s - loss: 0.5461 - accuracy: 0.8189 - 2s/epoch - 37ms/step\n",
            "Epoch 18/50\n",
            "64/64 - 2s - loss: 0.5504 - accuracy: 0.8110 - 2s/epoch - 37ms/step\n",
            "Epoch 19/50\n",
            "64/64 - 2s - loss: 0.5142 - accuracy: 0.8298 - 2s/epoch - 36ms/step\n",
            "Epoch 20/50\n",
            "64/64 - 2s - loss: 0.5060 - accuracy: 0.8337 - 2s/epoch - 36ms/step\n",
            "Epoch 21/50\n",
            "64/64 - 2s - loss: 0.5074 - accuracy: 0.8377 - 2s/epoch - 36ms/step\n",
            "Epoch 22/50\n",
            "64/64 - 2s - loss: 0.5038 - accuracy: 0.8377 - 2s/epoch - 37ms/step\n",
            "Epoch 23/50\n",
            "64/64 - 2s - loss: 0.4732 - accuracy: 0.8511 - 2s/epoch - 36ms/step\n",
            "Epoch 24/50\n",
            "64/64 - 2s - loss: 0.4686 - accuracy: 0.8511 - 2s/epoch - 37ms/step\n",
            "Epoch 25/50\n",
            "64/64 - 2s - loss: 0.4606 - accuracy: 0.8580 - 2s/epoch - 36ms/step\n",
            "Epoch 26/50\n",
            "64/64 - 2s - loss: 0.4461 - accuracy: 0.8615 - 2s/epoch - 36ms/step\n",
            "Epoch 27/50\n",
            "64/64 - 2s - loss: 0.4490 - accuracy: 0.8575 - 2s/epoch - 37ms/step\n",
            "Epoch 28/50\n",
            "64/64 - 2s - loss: 0.4317 - accuracy: 0.8758 - 2s/epoch - 36ms/step\n",
            "Epoch 29/50\n",
            "64/64 - 2s - loss: 0.4241 - accuracy: 0.8758 - 2s/epoch - 36ms/step\n",
            "Epoch 30/50\n",
            "64/64 - 2s - loss: 0.4155 - accuracy: 0.8803 - 2s/epoch - 36ms/step\n",
            "Epoch 31/50\n",
            "64/64 - 2s - loss: 0.4042 - accuracy: 0.8768 - 2s/epoch - 36ms/step\n",
            "Epoch 32/50\n",
            "64/64 - 2s - loss: 0.3972 - accuracy: 0.8857 - 2s/epoch - 36ms/step\n",
            "Epoch 33/50\n",
            "64/64 - 2s - loss: 0.3944 - accuracy: 0.8862 - 2s/epoch - 36ms/step\n",
            "Epoch 34/50\n",
            "64/64 - 2s - loss: 0.3789 - accuracy: 0.8916 - 2s/epoch - 38ms/step\n",
            "Epoch 35/50\n",
            "64/64 - 3s - loss: 0.3772 - accuracy: 0.8951 - 3s/epoch - 40ms/step\n",
            "Epoch 36/50\n",
            "64/64 - 3s - loss: 0.3756 - accuracy: 0.8926 - 3s/epoch - 39ms/step\n",
            "Epoch 37/50\n",
            "64/64 - 3s - loss: 0.3622 - accuracy: 0.9015 - 3s/epoch - 39ms/step\n",
            "Epoch 38/50\n",
            "64/64 - 2s - loss: 0.3562 - accuracy: 0.9015 - 2s/epoch - 37ms/step\n",
            "Epoch 39/50\n",
            "64/64 - 2s - loss: 0.3532 - accuracy: 0.8981 - 2s/epoch - 36ms/step\n",
            "Epoch 40/50\n",
            "64/64 - 2s - loss: 0.3466 - accuracy: 0.9075 - 2s/epoch - 36ms/step\n",
            "Epoch 41/50\n",
            "64/64 - 2s - loss: 0.3389 - accuracy: 0.9080 - 2s/epoch - 36ms/step\n",
            "Epoch 42/50\n",
            "64/64 - 2s - loss: 0.3403 - accuracy: 0.8971 - 2s/epoch - 36ms/step\n",
            "Epoch 43/50\n",
            "64/64 - 2s - loss: 0.3291 - accuracy: 0.9119 - 2s/epoch - 36ms/step\n",
            "Epoch 44/50\n",
            "64/64 - 2s - loss: 0.3231 - accuracy: 0.9114 - 2s/epoch - 36ms/step\n",
            "Epoch 45/50\n",
            "64/64 - 2s - loss: 0.3174 - accuracy: 0.9193 - 2s/epoch - 36ms/step\n",
            "Epoch 46/50\n",
            "64/64 - 2s - loss: 0.3133 - accuracy: 0.9159 - 2s/epoch - 36ms/step\n",
            "Epoch 47/50\n",
            "64/64 - 2s - loss: 0.3157 - accuracy: 0.9134 - 2s/epoch - 36ms/step\n",
            "Epoch 48/50\n",
            "64/64 - 2s - loss: 0.3092 - accuracy: 0.9174 - 2s/epoch - 36ms/step\n",
            "Epoch 49/50\n",
            "64/64 - 2s - loss: 0.2946 - accuracy: 0.9283 - 2s/epoch - 36ms/step\n",
            "Epoch 50/50\n",
            "64/64 - 2s - loss: 0.2961 - accuracy: 0.9179 - 2s/epoch - 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a6232e490>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retorna(y):\n",
        "  resp = []\n",
        "  for yi in y:\n",
        "    vmax =max(yi)\n",
        "    for idx, x in enumerate(yi):\n",
        "      if(x == vmax):\n",
        "        resp.append(idx)\n",
        "  return resp"
      ],
      "metadata": {
        "id": "oZpcAHqAcc2P"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_model.evaluate(X_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1WjQJzCoJbp",
        "outputId": "956c0f68-8bb2-427b-854b-044c0dc8c76f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 - 2s - loss: 0.7733 - accuracy: 0.7213 - 2s/epoch - 123ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict=model_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy_bi00toakb",
        "outputId": "9928b617-6308-44da-fa6a-457d977e9017"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpzdBCZUp2wj",
        "outputId": "d23f987b-d1f1-4f24-fe65-0113dd43f9c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_calc = retorna(predict)\n",
        "y_test = retorna(np.array(y_test))"
      ],
      "metadata": {
        "id": "WlB25NH9obtJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_calc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEDV8C1Qoe2q",
        "outputId": "f6227579-2c6a-44eb-c71a-6802c21c4c6b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 68,   2,   1,   7,   3,   0],\n",
              "       [  0,  70,  15,   4,  11,   0],\n",
              "       [  0,   7,  61,   2,  10,   2],\n",
              "       [  7,   1,   3, 105,   1,   2],\n",
              "       [  1,  20,   8,  13,  54,   1],\n",
              "       [  1,   5,   0,   7,   7,   7]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print('\\n\\n', classification_report(y_test, y_calc, target_names=tipos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpUUMcTpolUA",
        "outputId": "8814eae4-00e0-4133-fb16-4d4a6cb26f7f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.88      0.84      0.86        81\n",
            "       glass       0.67      0.70      0.68       100\n",
            "       metal       0.69      0.74      0.72        82\n",
            "       paper       0.76      0.88      0.82       119\n",
            "     plastic       0.63      0.56      0.59        97\n",
            "       trash       0.58      0.26      0.36        27\n",
            "\n",
            "    accuracy                           0.72       506\n",
            "   macro avg       0.70      0.66      0.67       506\n",
            "weighted avg       0.72      0.72      0.71       506\n",
            "\n"
          ]
        }
      ]
    }
  ]
}